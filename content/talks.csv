id,title,room,day,no,elevator_pitch,prerequisite_knowledge,audience_takeaway,talk_format,audience_python_level,audience_expertise,track,lang_of_talk,lang_of_slide,description,name,profile
100001,TBD,,1,,,,,Keynote,,,,,,,芝世弐,"2017年に独学で機械学習を始め，同年に初参加の将棋電王トーナメントにて準優勝。
翌年には世界コンピュータ将棋選手権に初参加で優勝してしまう。
以後，2019年および2020年の大会では準優勝と参加大会の平均順位が1点台という驚異的な強さを誇る。
本職は数値シミュレーションを主とする研究者であるが最近の発表は大半将棋に関するものになっている。
趣味はビールと将棋観戦。

In 2017, he began self-taught machine learning, and in the same year, he became the runner-up in the Shogi (Japanese Chess) Den-O tournament he participated in for the first time.
The following year, he won the World Computer Shogi Championship even though it was the first time he participated.
Since then, he has been a runner-up in the 2019 and 2020 meets and has a phenomenal one-point average ranking in the participating meets.
He is a researcher who mainly works on numerical simulations, but most of his recent publications have been about shogi.
His hobbies are beer and watching shogi."
100002,TBD,,2,,,,,Keynote,,,,,,,Rich Jones," Rich is the cofounder of Gun.io, a global consulting firm staffed by the best hackers from the Free and Open Source software community. He is the author of Zappa, the leading server-less Python framework, used by thousands of companies and users to save time and money for their web deployments. He has worked on everything from cloud GPU clusters for medical and scientific computing to mobile peer to peer file sharing applications, and on everything in between. In his spare time, he enjoys skateboarding, dirty southern trap music, and Laphroaig.

RichはGun.ioの共同設立者です。
Gun.ioはグローバルなコンサルティングファームで、フリーソフトウェアやオープンソースソフトウェアのコミュニティから来た最も優秀なエンジニア（ハッカー）たちが所属しています。
彼は、Pythonにおける主要なサーバレスフレームワーク、Zappaの作者です。
Zappaは、何千もの企業やユーザによって使われ、Web開発における時間と費用を節約しています。彼は医療や科学計算向けのクラウドGPUクラスタからモバイルのピア・ツー・ピアのファイル共有アプリまで、そしてその間にあるあらゆるものに取り組んできました。彼の趣味はスケートボード、サザン・ヒップホップと、ラフロイグを飲むことです。"
100011,TBD,#pyconjp_1,1,1,,,,Invited talks(45min),,,,English,,,,
100012,ある個人開発 OSS の歩み：5 歳になった Janome のこれまでと，これから,#pyconjp_1,1,2,2015年に生まれた Janome は，今年で開発5年目となりました。PyConJP 2015での発表から，これまでに行ってきた機能開発や改善について，技術的な解説を交えつつ振り返ります。また，今後追加していきたい機能や，個人開発のモチベーションをゆるく長く保ち続けるコツについてもお話できればと思います。,,,Invited talks(45min),,,,Japanese,,https://pyconjp.blogspot.com/2020/08/invited-talks1.html,打田智子,2007年に筑波大学大学院システム情報工学研究科の博士前期課程を修了後，いくつかのIT系企業を経て，現在は株式会社 LegalForce の R&D チームで検索システムや言語処理の研究開発に従事。2015年に Python 製日本語形態素解析ライブラリ Janome を OSS として公開し，同年 PyConJP にも登壇。Janome の開発をほそぼそ続けながら，2019年から OSS 検索エンジンライブラリ Apache Lucene のコミッターも務める。興味のある分野は情報検索と機械学習，自然言語処理。海の見える部屋で猫と暮らすのが夢。
100013,続・小さく始めて大きく育てるMLOps2020,#pyconjp_1,1,3,"乱立するJupyter Notebook、身元不明なデータ、再現しない学習結果、引き継ぎできない実験コード…
そんな課題を解決するべく、今日から始められるMLOpsを紹介します。
趣味の機械学習から研究室での実験管理、プロダクトでの運用まで、広く参考になれば幸いです。",,,Invited talks(30min),,,,Japanese,,https://pyconjp.blogspot.com/2020/08/pycon-jp-2020-3-announcement-of-invited.html,岩崎祐貴,"株式会社サイバーエージェント AI Lab Research Engineer。
2014年にサーバーサイドエンジニアとして入社後、インターネット広告事業でScala、JavaScript、Pythonを使った配信基盤や広告レンダリングエンジン、効果予測システムを作成。
フロント・インフラ・データ分析業務を経て、2017年から現職。
クリエイティブリサーチグループにて広告のテキストや画像、動画等の高次元特徴から配信影響を紐解く研究に従事。
ゲームでは魔法使いのような紙耐久アタッカーが好き。"
100014,Metaclass？Descriptor？完全に理解した()あなたに,#pyconjp_1,2,1,"Python3.6で追加されたとあるダンダーメソッドが、DescriptorやMetaclassに大きく影響を与えました。
というのはどういうことなのか。完全に理解したあなたと私のために、metaclassとdescriptorの復習から始めます。
存在は知っているけれどどう使われてるの？となりがちなMetaclassとDescriptorを「ちゃんと」理解していきましょう。",,,Invited talks(45min),,,,Japanese,,https://pyconjp.blogspot.com/2020/08/invited-talks2.html,露木誠,"2000年頃にファッションジュエリー業界からIT業界へ移り、以来ソフトウェアエンジニアとして働いています。
Python、Java、Perl、Rubyなどのプログラミング言語を用いてB向けC向けを問わずさまざまな開発に従事してきました。
ソフトウェアエンジニア・チーフアーキテクト・テックリードなどとして開発に携わるのみならず、プログラミング講習の講師や自社サービス用工場の立ち上げなど、開発から外れた仕事もしてきました。
ここ数年はエンジニアが働きやすい環境づくりなどにも関わっています。"
100015,過去2回の登壇内容からのPython×ドローンの進化、アップデート内容と今後について展望,#pyconjp_1,2,2,"過去2年(2017，2018)のPyConJP発表からの進化・進捗などをまとめて、Pythonとドローンをどのように扱い、活用すべきかを自身の経験も踏まえてお話をします。
2017年および2018年の発表時には何ができて、何が問題・不足したのか。そしてその後はどのように解決したのか。
果たしてPythonとドローンの組み合わせは良かったのか？
現在市販されているミニドローン「Tello」がPythonでプログラミングできます。では、実際にどのような動作ができるのかを調査しまとめます。
最後に、ハードウェアとソフトウェアの両方を実験して感じたことをまとめ、トークします。",,,Invited talks(30min),,,,Japanese,,https://pyconjp.blogspot.com/2020/08/invited-talks4.html,片寄里菜,"片寄里菜さんは、幼い時より航空機に興味があり、もっと学びたいという想いから東海大学工学研究科・航空宇宙学専攻の博士課程前期に進み、ヘリコプターなど垂直離着陸機の研究を行っていま
大学院修了後は、WEB関連の仕事をしながら個人的な研究テーマを進め、Pythonと出会いました。Pythonでは主にRaspberryPiを使ったモノを動かすプログラミングに視点を置き、開発などを行っていました。
PyConJPには2016年に初参加。Pythonの楽しさや奥深さを知り、様々なコミュニティに参加し友人・知人を増やしたようです。またPyLadiesTokyoコミュニティ参加をきっかけに、今ではスタッフとして活動しています。
登壇経験としてPyConJP2017と2018ではドローンとPythonに関する内容で発表・実演を行いました。またPyCon Thailand2019ではPyLadiesのコミュニティ活動に関する海外の登壇経験もあります。PyConUSなど海外のPyConに参加している経験もあり、精力的に活動を行っています。
ご自身の仕事は2018年に株式会社moegiを創業し、計測用のスマホアプリなどを開発。日本だけでなく世界の空の活用法や問題点なども調べ、航空機分野の開発者として活躍できるようにと日々活動をしています。"
100021,オープニング,,1,,,,,,,,,,,,,
100022,クロージング,,1,,,,,,,,,,,,,
100023,オープニング,#pyconjp_1,2,,,,,,,,,,,,,
100024,クロージング,#pyconjp_1,2,,,,,,,,,,,,,
100025,スポンサーバネルディスカッション,,2,,"ランチタイムにスポンサーによるパネルディスカッションを開催します。
ランチが始まったらご飯を準備いただき、パネルディスカッションはご飯を食べながら是非お聞きください。",,,,,,,,,,,
100026,一般社団法人PyCon JP Association 公開会議,,1,,,,,,,,,,,,,
202715,2020年代のコンテナ時代のPythonアーキテクチャ&デプロイ,#pyconjp_4,1,1,機械学習をAPIサービスとして実装するか、バッチ処理にするか、はたまた通常のウェブアプリを実装するかによらず、デプロイ手段として重要度が増しているのがコンテナです。ローカルで開発環境を作る上でも便利です。コンテナに適したアプリケーションの作法を学ぶとともに、asyncioを使うことでそのパフォーマンスを引き出します。最後にそれらをコンテナにまとめてデプロイする方法を学びます。,"Dockerやコンテナとはなにか？Dockerfileを書ける知識については問わない
クラウドとはなにか？
ウェブアプリケーションを何かしら作ったことがある","12 factors appに従った今どきのアプリケーションに求められる特性
Python 3時代のハイパフォーマンスなウェブサービスの実装方法
ビルド時間が短く、性能がよく、サイズも良く、セキュリティも高いDockerイメージを作る",Talk(45min),Advanced,50%,Web programming (including web frameworks),Japanese,Both,"クラウドサービスがどんどん拡充されていく中、大きなウェイトを締めてきているのがコンテナです。本番環境で活用している事例も多く、今後導入を考えている人もどんどん増えています。開発環境の一部としての利用もますます増えています。

https://www.publickey1.jp/blog/20/docker142idc_japan.html
https://www.jetbrains.com/lp/python-developers-survey-2019/

コンテナを知ることで、技術革新の高速道路に乗りやすくなります。Pythonの用途は機械学習を中心として広がっていますし、以前からのウェブアプリケーション開発もあります。そのどの用途であっても、APIサーバー、ウェブサービス、バッチを作ることになりますが、それらはコンテナとして動かすことができ、従量課金のサーバーレスといったコンテナネイティブな運用方法に乗せることができます。費用的にも、管理的にもメリットが得られます。

コンテナで動くアプリケーションにもいくつか作法があります。コンテナという枠の中で動くために自由に触れません。作法に従うことでトラブルを減らすことができますし、コンテナネイティブな設計はシンプルになるため、開発の手間も少なくなります。ウェブフロントエンドのJavaScriptの開発とセットで行う方法など、開発環境、デバッグ方法についても紹介します。

コンテナ中で動くアプリケーションは特定のCPU/メモリの中で動作します。つまり、CPUを引き出すのがコンテナ時代にはハイパフォーマンスに動くアプリケーションの要件になります。Python2がEOLになることで、Python3のasyncioを活かしやすくなります。すでにasyncioを活かすライブラリがたくさん出ています。asyncioの仕組みや基本を紹介したあとに、Python 3時代の高速なウェブアプリケーションやバッチ処理の実装方法についても紹介します。

最後に、Dockerイメージの作成方法を学びます。Dockerイメージ作成も、少し知識がないと、色々選択肢があって迷います。用途に合わせた最適なベースイメージを選択する方法、そして今どきのDockerの機能を生かした効率的なDockerfileの書き方を紹介します。

* 自己紹介(3min)
* コンテナ(15min)
  * コンテナとはなにか
    * コンテナは開発支援ツール
    * コンテナはデプロイツール
    * Lambda/Functionsとの違い
  * 12 factors appに従ったPythonコンテナの作成
    * デバッグ・デプロイ
    * コンテナで動くアプリケーションの今どきのログ出力
    * 分散トレーシング
* コンテナ時代のモダンPythonアーキテクチャ(15min)
  * CPUバウンドとI/Oバウンド
  * コンテナやクラウドの性能を引き出すには？
    * 3系ならasyncio
      * Starlette
      * aiohttp
      * asyncpgなど
* パッケージングしてデプロイ(10min)
  * ビルド時間が短く、性能がよく、サイズも良く、セキュリティも高いイメージを作る
* まとめ(2min)",shibukawa,Python 2.1ぐらいからのPythonユーザー。エキスパートPythonプログラミングの翻訳者の1人。Python以外にはTypeScript/Go/C++あたり。のユーザー。
203955,Python 3.9 時代の型安全な Python の極め方,#pyconjp_2,1,1,"Python は動的型付き言語ですが、「型ヒント」によって変数などに型を定義できます。型ヒントを活用すれば IDE での補完が強力になったり、静的解析で""型安全""にできるなど、動的型付き言語でありながら、型の恩恵を得ることができるのです！
型ヒントの環境は年々進化しています。Python 3.9 でのアップデートや、Google/Microsoft による型チェッカーの公開などもあり、型ヒントを書いたことがあっても最新情報をキャッチアップができていない方も多いと思います。

JX通信社で型ヒントを数年活用して「型の恩恵」を得てきたスピーカーが、最新の型ヒントの活用方法を紹介します。","Python 3 の基本的な文法。必須ではありませんが、静的型付け言語の経験などがあるとスムーズです。
","- 最新の型ヒントの使い方
- mypy などを活用した、型安全な Python の書き方
- 実務での型ヒントや mypy の活用方法",Talk(45min),Intermediate,0%,Python core,Japanese,Japanese only,"このセッションでは、Python 3.5 で公式サポートされた「型ヒント (Type Hint)」について、2020年現在の最新状況を紹介します。

Python は動的型付き言語ですが、型ヒントを使うと、ソースコード上の変数などに型の情報を付与できます。サードパーティーツールと組み合わせれば IDE での補完や型の誤りのチェックなど、静的型付き言語のようなメリットが得られます。
実際に、私が所属する JX 通信社では、なるべく ""型安全"" な Python を書いてチーム開発する文化があり、型を意識した Clean Architecture の実践、CI での型チェックなども行ってきました。

また、Python の型ヒントを取り巻く環境は年々進化しています。文法自体のアップデートもありますが、typing モジュールや typeshed が拡充されていたり、mypy 以外の型チェックツールも Google や Microsoft によって公開されています。

このセッションは、型ヒントを実務で活用してきた経験を活かし、「Python3.9時代」の型ヒントを紹介するのがメインテーマです。主に次のようなトピックを扱います。
1. 型ヒントに関する概要
2. Python 3.9 を想定した型ヒントの使い方
3. 2020年現在のサードパーティーツールによる静的型チェック
4. JX 通信社での実事例

構成とタイムラインは以下の通りです。

- 導入 (7min)
  - 型ヒントとは何か、何でないか
  - 型ヒントでできること
- 型ヒントの書き方 (15min)
  - 基本的な書き方
  - ジェネリクスなどの高度な型の紹介
  - Protocol を使った構造的部分型の紹介
  - Python 3.9、3.8 でのアップデート
- サードパーティーツールの活用 (10min)
  - mypy の紹介
  - pyright、pytypeなどの新しい型チェックツール
  - pydantic の活用
- 型ヒントを実務に活かす (10min)
  - CI に組み込むときのテクニック
  - 型定義されてないライブラリに出会ったとき
- まとめ (1min)
- 質疑応答 (2min)
",yamitzky,株式会社JX通信社の開発担当役員(CDO)。エンジニアとしては、Scala や Python を使ったデータ解析や TypeScript でのフロントエンド開発などを経験
203572,unittest.mockを使って単体テストを書こう 〜より効率的で安定したテストに〜,#pyconjp_3,1,1,"このトークは、Pythonで単体テストを書いたことはあるけれども、モックオブジェクトは知らないという方向けです。
同じテストケースなのに実行結果が異なったり、テストの実行速度が遅くて悩んだことはありませんか。
そんな時の解決策として、モックオブジェクトがあります。
これはプロダクトコードの一部をテスト用オブジェクトに置き換えるというものです。
これをPythonで使うには、unittest.mockモジュールを使います。
このトークでは、モックオブジェクトの基本的な考え方とunittest.mockモジュールの使い方を扱い、
聴衆の方がPythonでモックオブジェクトを適切に使えるようになることを目的としています。","- Pythonで単体テストを書いた経験が必要です。(unittestモジュールでもサードパーティのテストライブラリでもどちらでも構いません）
- unittestモジュールの基本的な文法(assertEqualやassertRaisesなど)を知っている前提なので、単体テスト自体の文法の説明はしません。
- unittest.mockモジュールを利用したことがあると理解しやすいですが、概念や使い方から説明しますので必須ではありません。","モックオブジェクトの考え方
- モックオブジェクトを使う目的
- モックオブジェクトの使い方
- 使い方アンチパターンとその対応策

unittest.mockモジュールの使い方
- unittest.mockモジュールの基本的な文法
- unittest.mock.Mockとunittest.mock.MagicMockの仕組み
- unittest.mockを使って困ったこととその対策
- datetime.datetime.nowをモックするには
- unittest.mock.patchが当たらない原因と対策
- ある関数が呼ばれたことだけテストするには
- 外部APIへのリクエストを含む関数をテストするには",Talk(45min),Intermediate,50%,Tips of development with Python,Japanese,Japanese only,"### 話さないこと
* テスト実行に便利なツールの紹介(coverageなど)
* pytestの紹介及びunittestとの比較
* E2Eテスト、結合テストの話


### 話すこと
単体テストの目的(3分)
単体テストの目的
単体テストを書くメリット

単体テストの理想像(3分)
単体テストは下記の条件が揃っているべきです
- 速く実行されます
- 常に同じ条件下で同じことがテストされます
- 外的要因を排除します
- 1つのテストメソッドは1つのことのみを確認していなければなりません
- テスト対象の関数の振る舞いを担保します

単体テストでモックオブジェクトを使う理由(5分)
- モックオブジェクトを使っていないためテストが失敗したり成功したりする例
- モックオブジェクトの説明
- モックオブジェクトを使った解決策の説明

Pythonのunittest.mockの基本的な使い方(10分)
- 具体的なコードを用いて説明します。


unittest.mock.Mockとunittest.mock.MagicMockの仕組み(8分)
- 具体的なコードを用いて説明します。

モックオブジェクトアンチパターン(5分)
- モックオブジェクトをメンテナンスしない故に、テストは通っているのにバグが発生
- よくテストされた箇所、もしくはテストが不要なほど細分化された箇所のみをモックオブジェクトに置き換えるべきです
- TypeHintで精査して変更した箇所に他の箇所が型違反していないか確認することでアトリビュートの齟齬によるエラーを防げます


unittest.mockモジュールを使って困った点とその対策(5分)
- unittest.mock.patchが当たらない
- assert_called_once_withなど、関数が呼ばれたことを確認する方法
- APIのレスポンスをモックオブジェクトに置き換えることで、外部- APIを呼び出す関数の振る舞いをテストします
- datetime.datetime.nowをモックオブジェクトに置き換えられない場合、datetime.datetime.nowを引数に持たせるかPythonの3rdパーティライブラリ「freezegun」を使ってテストします
",みずき,"2018年に趣味でPythonを始め、2019年1月からずっとPythonでWeb開発に従事しています。
2020年4月から現職。"
203929,数理最適化×機械学習コラボレーションによる課題解決,#pyconjp_5,1,1,"データサイエンスの潮流の中の一つとして、機械学習と数理最適化を組み合わせて課題解決をする流れが出来つつあります。
機械学習の得意なところ、数理最適化での得意なところをコラボレーションさせることによって、データ分析結果から意思決定まで繋げることが可能となります。
具体例としては①メーカーでの需要予測→生産計画立案や物流計画の立案、②人材サービスにおけるスキルシート分析→人材アサイン計画の立案といった例があげられます。このような課題をPythonとPandas、Scikit-Learn、Google OR-Toolsでシームレスに実現することができます。本発表ではGoogle OR-Toolsを使ったコーディング方法、組合せ最適化問題のモデリング、問題分割や計算の高速化方法といった実践的なポイントを事例とともに説明します。","機械学習という言葉を聞いたことがある
数理最適化という言葉を聞いたことがある",Pythonの機械学習/数理最適化ライブラリの名前、使い方、それらを組み合わせた課題解決方法,Talk(30min),Intermediate,50%,Data Science / Machine Learning,Japanese,Japanese only,"データサイエンスの潮流の中の一つとして、機械学習と数理最適化を組み合わせて課題解決をする流れが出来つつあります。
本発表では、Pythonによる機械学習と数理最適化の組み合わせにより課題解決をする方法をご紹介します。

機械学習では、与えられたデータについての判別、分類、予測といったことを得意としています。対して、数理最適化では制約条件と、目的とする評価指標を定義し、その評価指標を最大化（もしくは最小化）する最適解を導きだす、意思決定をするといったことを得意としています。これまでは、何かのデータをそのまま使って数理最適化で意思決定をすることが実施されてきましたが、近年ではデータの蓄積やデジタルトランスフォーメーションにより、ユーザの抱えている問題が複雑化高度化して、解決すべき課題も難しくなってきています。

一例を挙げてみると、メーカーが販売計画や物流計画を作成するとき、元となる過去のデータから、未来の状態を予測して意思決定をしなければなりません。また、過去のデータが文書データである場合には、最適化で利用できるよう数値に変換をしなければなりません。このように、機械学習や自然言語処理を活用して変換や予測した結果を用い、数理最適化で意思決定をすることでデータ分析から、計画立案という意思決定までをPythonを使って実現することができます。

本発表では、弊社での取り組みの一つとして、簡単な自然言語処理と数理最適化を組み合わせた事例を紹介いたします。弊社では人材派遣業をおこなっておりますが、エンジニアの採用という業務の中で、効率よく面接計画を立案しなければならないという課題がありした。実際には、ベテランの営業管理者が、営業担当者のスキルと採用応募者のスキルを照らし合わせ、マッチングの高い組合せでスケジュールの合う担当者を割り当てる、といった作業を毎日実施していました。

営業担当者のスキルとしては、金融、製造といった業種、PythonやJavaといったプログラミング言語、プロジェクトマネージャや、プロジェクトリーダー、SE、PL、PG、データサイエンティストといった担当領域など、いくつかのベクトルがあり、同ように、エンジニア側にもいくつかのベクトルがありました。これらの過去データを機械学習にかけてマッチング度を算出し、営業担当者と採用応募者の面接可能日時を制約条件として、全体的なマッチング度が最も高い面談スケジュールを立案することが可能となります。その効果として、営業部全体での業務負荷低減と効率的な人材確保を期待することができます。

必要なものはPythonとPandas、Scikit-Learn、Google OR-Toolsという誰もが利用できるPythonパッケージです。本発表では事例の他に、Google OR-Toolsを使った基礎的なプログラミングから、組合せ最適化問題のモデリング、問題の分割や計算の高速化といった実践的なポイントも事例とともに紹介いたします。",鈴木　庸氏,"株式会社リーディングエッジ社にて、PythonとOR-Toolsによる需要予測/物流計画最適化を担当しています。Python3スキルアップ教科書の共同著者、オペレーションズリサーチ学会員。

twitter -url:https://twitter.com/suzuki_youji"
203640,Machine Learning Outside the Kaggle Lines,#pyconjp_5,1,2,"Kaggle competitions are great, but what do you do when you have a cool idea for your own machine-learning project? Learn about all the dirty data, bugs of others, and keeping it all running, when building from zero to production. Hear about the mistakes that I've made so you can avoid them yourself.","This talk is for people who are familiar with the popular tools of machine learning in Python, but have little experience with real-world machine learning projects or applications. They know about, and probably have used, libraries such as Numpy, Pandas, Scikit-Learn, and Tensorflow, but mostly in the the context of a class project or Kaggle competition.","From this talk, the audience will learn more about the challenges and pitfalls that come with building their own machine learning applications from scratch, so as to better avoid them and increase their chances of producing a complete, successful project.",Talk(30min),Intermediate,50%,Data Science / Machine Learning,English,English only,"Machine learning is more art than science, and it isn't alway clear how you go from Kaggle competitions to building your own machine learning project from scratch. You have a cool idea, but how do you turn it into an application that you can show off to your friends, basking in the warmth of their envy? More importantly, what mistakes do you need to avoid in order to keep the hope of such basking alive?

Come along and hear of my missteps, assumptions exposed and exploded, and the unpleasant surprises that come from doing machine learning in the wild. You'll learn about how to deal with haphazard data entry, depending on the kindness of strangers, boxes of different shapes and sizes, and, finally, what to do when all of this changes, because it will.

If you're interested in machine learning and are familiar with the basic tools and techniques, but are unsure of how to take a project idea to production, this talk will at least show you what not to do and how not to do it.

Outline:
1. Introduction (2 mins)
    * Explain Aussie Rules Football, footy tipping, and inspiration for the project.
    * Set up structure of the talk: two seasons-worth of work, with what I did wrong in season one, and how I did it better (but not perfectly) for season two.
2. Understanding the Problem (2 mins)
    * Season one: I just built a model to predict winners and losers.
        * I didn't realise that one has to predict margins as well.
    * Season two: I built a model to predict margins.
3. Collecting the Data (5 mins)
    * Season one: I wrote my own web scraper.
    * Season two: I imported data from a package that did the web scraping for me.
        * It's good to share the work rather than go it alone.
        * Use the right tool for the job: importing data from an R package can be less work than getting it yourself.
    * Season one: I panicked and changed my data source, because the original source didn't update at the beginning of the week.
    * Season two: I updated data in accordance with scheduled updates to websites.
        * It's important to understand the source of data in addition to the data itself.
4. Cleaning the Data (5 mins)
    * Season one: I filled and/or dropped blank data and hoped for the best.
    * Season two: I added a lot of assertions about the shape and content of data to raise errors early.
    * Explicit assertions about your assumptions catch buggy data that wouldn't raise errors otherwise.
    * With dynamic data sources, unexpected bugs pop up regularly; static unit tests won't catch them.
5. Model Selection (2 mins)
    * Season one: I started with multi-layer RNNs, because deep learning is the best, right?
    * Season two: I tested a wide variety of model types, and NNs didn't have the best performance.
    * Test your assumptions, because sometimes the results will surprise you.
    * Interpretability and maintainability matter, because this isn't something you turn in for the best possible score then forget about.
6. The Joy of Production (5 mins)
    * Season one: I deployed to Heroku right before the season started, and it didn't work.
        * Some C libraries weren't available in that environment.
        * I deployed a Docker container to make sure all dependencies were in production.
    * Season two: I deployed a container to Heroku right before the season started, and it didn't work.
        * New player data set was too big and exceeded the free-tier memory limit.
        * I paid for a larger server, until I could change the app's architecture.
    * Know the differences between local and production environments, especially the limitations of the latter.
7. Conclusion (2 mins)
    * Season one: despite the mistakes, I won my office footy tipping competition by one whole point.
    * Season two: despite the improvements, I lost my office footy tipping competition by five points.
    * Doing things the right way improves your chances, but doesn't guarantee victory.",Craig Franklin,"Craig is a professional web developer by way of digital marketing and an amateur data scientist by way of wanting to understand what in the world all these numbers mean. Writing Ruby by day, his passion projects are centered around sports, data, and machine learning, all for the ultimate prize of bragging rights. Originally from the suburbs of Seattle, WA, he currently lives in Melbourne, Australia."
203235,PythonからGolangに変更してから再びPythonに戻った理由,#pyconjp_2,1,2,"会社でPythonでGolangを使うことに決めましたが、Pythonに戻った経験を共有します。
そして1ヶ月ぶりにPythonを使ってMirco Serviceをランチすることができました。
なぜGolangに移ることに決め、戻ってきた理由を共有します。
Mirco Serviceの2つをリリースし、PythonとGolangを一緒に使用した経験をもとに、Pythonがなぜこのように生産性が良く、愛されるのかについて話します。","PythonでHTTP Request(requests), JsonやXMLを使用する方法。

Djangoサーバーを作った経験があれば良いですが、なくても理解する上で大きな無理はなさそうです。

そして、Golangに関する基本的な知識があればやはりいいです。 DDDやMSAについて聞いたことがある人なら理解するのに役立つでしょうが、メインテーマではないので大丈夫です。","PythonがGolangに比べて持つ強みは何か(Pythonの魅力)!

Micro Serviceに合わせて言語を選択する方法

PythonでNetwork Requestを送り、Json/XMLを処理する方法

Golangという言語の簡単な使い方",Talk(45min),Intermediate,50%,Tips of development with Python,Japanese,Both,"BUZZVIL(my company)ではPythonとGolangを使用してMonolithic ArchitectureでMicro Service Architectureとして、漸進的に変えています。
したがって、新たに製作するMicro ServiceをGolangで作ったが、すでに使用していたPythonに比べ、不便な点が多かったです。 したがって、Micro Serviceの発売まで長い時間がかかるようになりました。
その次のMicro Serviceは再びPythonを使用するようになり、はるかに短い期間内にオープンが可能になりました。
その過程でどのような点がプロジェクトの進行に影響を与え、Pythonのどんな点が生産性、恒常を持ってくるのか分析しました。


導入
- 自己紹介(3min)
- 会社がMonolithicからMSAに移った背景について (4min)

1. Type System (8min)
1-1. Introduce Golang.
1-2. Duck Typing / Structural Typing
1-3. Functional Programming

2. HTTP Client (8min)
2-1. Python requests
2-2. Golang net/http
2-3. What is the difference?
2-4. Concurrency

3. Handling JSON (8min)
3-1. Python json
3-2. Golang encoding/json
3-3. What is the difference?
3-4. XML の場合どうなるか。

4. 開発環境(8min)
4-1.ORMではどう違うか
4-2. Package 管理者(pip / go mod)
4-3. Lint / Test / Etc


仕上げ

- 現在のプロジェクト結果(2~3min)
- 質疑応答(3min)",Las,恋人に従ってプログラミングを学ぶとプログラマーになった人。 プログラミングを教える高校を出てすぐ会社で仕事中。
203891,Pythonパッケージの影響を歴史から理解してみよう！,#pyconjp_4,1,2,"distutils、easy_install、setuptools、pip、tox、venv、pipenv、poetry などの Python パッケージツールの起源を考えたことがありますか？ このトークでは、「Pythonソフトウェア Distribution」の歴史を紹介します。

コミュニティが Python パッケージを提案する以前、どのように大企業は Python パッケージを作成していたか、ご存知ですか？このトークでは、とある大企業が自作Pythonパッケージシステム運用に苦戦した過去、そこから学んだ教訓、そして最終的にコミュニティのPythonパッケージを採用した理由について紹介します。

Python パッケージの歴史や、大企業が苦戦したPythonパッケージシステム運用話について興味があれば、ぜひ参加してください。","【Prerequisite knowledge】
- Basic experience in python packaging. Related technical terms: distutils, setuptools, pip, and PyPI.

【Optional knowledge】
- Newer Python packaging tools: bento, twine, flit, pipenv, and poetry.
- Famous PEP mentioned in Outline of Description.","- Well-organized history timeline with detail. 
- Learn the history of python packaging and the reason behind different solutions.
- Learn the build system experience from the speaker, and be able to make right decision in the first place if they meet similar problem in the near future.",Talk(45min),Intermediate,50%,Python core,Japanese,Japanese only,"There's a [talk by Dustin](https://www.youtube.com/watch?v=na0hQI5Ep5E) presented similar ""time travel"" content from community perceptive. In this talk, I will present the impact of the evolvement of python packaging and provide my company as an example which built before Python community had Python packaging solution.

The talk contains 2 parts: History (Fact) and Treatment (Action).

In the 1st section, I will cover history of ""Python Software Distribution"" along with few PEP and their corresponding tools, including Metadata (RFC822, PEP241, 314, 345, 426, 459, 566), Database (PEP262, 376, 427, 440), and Runtime (PEP405, 374, 582) and share my insight from the history.

In the 2nd section, I will talk about the treatment for company started before those idiomatic tools built, our learned lessons, and available treatments in 2020.

---

Outline and timeline are as follows.

1.自己紹介と動機 【3分】
2.Python パッケージの歴史 【18分】
  - Python1（2.5分）
    - ソースコードを他の人と共有するには？
  - Python2（3.5分）
    - メタデータ (PEP241 & PEP314 & PEP345 / distutils / setuptools)
    - Python Package Index (easy_install)
    - ソフトウェア Distribution (PEP262)
  - Python3 （5.5分）
    - より良いメタデータ (PEP426 & PEP459 & PEP566)
    - パッケージの依存関係管理 (PEP386 & PEP440 & PEP508)
    - PyPI がパッケージのホスティングを開始 (pip / twine / bento / flit)
    - ソフトウェア Distribution (PEP376 / PEP425 & 427 & 491)
  - Python2+3 & Other Problems（5.5分）
    - 複数 Python バージョンのサポート (tox / virtualenv / PEP405/pipenv)
    - 複数 OS での Python のサポート (PEP513 & PEP517 & PEP571 /  Conda & Anaconda (2014))
    - Poetry: 1つのツールですべてを処理 (PEP517 & PEP518 & PEP582)
3. 歴史から学ぶこと 【4分】
  - Python パッケージの進化
4.コミュニティが Python パッケージを解決する前の挑戦  【12分】
  - Python パッケージに標準はない
  - ゼロからパッケージシステムを構築する
  - 弊社のパッケージシステムの概用
  - 弊社のパッケージシステムの教訓
    - なぜ古いOSを維持するのか?
  - コミュニティソリューションに移行する理由
    - コミュニティソリューションはより速く確実に拡張される
5.コミュニティが Python パッケージを解決した後の挑戦 【5分】
  - 企業とコミュニティの理想的な関係
  - メタデータ標準の数 ∝ ツールの数
    - 2020 年に Python アプリケーションを作成したら...
    - PyPI へパッケージをアップロードしたかったら...
6.まとめ 【3分】

---

7.Python パッケージの歴史に関する資料【0分】
  - 歴史
    - Dustin Ingram @ SciPy 2018: Inside the Cheeseshop: How Python Packaging Works
    - Kenneth Reitz @ PyCon 2018: Pipenv: The Future of Python Dependency Management
    - Clinton Roy @ Kiwi PyCon X (2019): The Packaging Lifecycle with Poetry
    - History of packaging written by Martijn Faassen
- パッケージ
    - Dave Forgac @ PyOhio 2015: Python Packaging from Init to Deploy
    - Elana Hashman @ PyCon 2019: The Black Magic of Python Wheel
    - Official Document: Packaging binary extensions (2013)
- デプロイ（仮想環境）
    - Carl Meyer @ PyCon 2011: Reverse-engineering Ian Bicking's brain: inside pip and virtualenv
    - Bernat Gabor @ EuroPython 2019: Status quo of virtual environments",Kir Chou,A code monkey builds search services in Amazon jungle. This will be the 4th year of his presence in PyCon JP.
203810,関数型Pythonアンチパターン,#pyconjp_3,1,2,"今日関数型プログラミングは一般的技法になりつつあります。うまく取り入れれば、状態変化によるバグを追放し、簡潔なコードを書けるでしょう。
ただし、Pythonの特性を考慮せぬまま他の言語の関数型スタイルを真似ると、趣味的で読みづらいコードになりかねません。
このトークでは、Pythonで実用的なコードを書く上で、たとえ関数型であっても避けるべき書き方を紹介します。具体的には、以下のアンチパターン／パターンを扱います。

* 長い式、複雑なlambdaを書く／式を名付ける
* map・filterを多用する／内包を使う
* 内包やreduceを濫用する／ループを書き、隠蔽する
* クロージャを濫用する／適切にクラスを定義する","Pythonの基礎的な文法の理解。
関数型プログラミングについての基礎知識や、関数型言語を扱った経験があると理解しやすいですが、必須ではありません。","* 関数型プログラミングとは何かという抽象的な理解
* 関数型プログラミングで可読性を壊さないようにするTips
* Pythonicで実用的なコードにおいて、内包表記や高階関数を活用するTips",Talk(30min),Beginner,0%,Python core,Japanese,Japanese only,"まずトークの目標として、いわゆる関数型言語に似たコードを書く方法ではなく、実用的な関数型プログラミングの方法を追求することを述べます。ただし何が良いコードか、Pythonicなコードかということに客観的基準はないことを強調しておきます。
次に関数型プログラミングを次の2点によって定義し、その利点を説明します。

* 高階関数の多用: 抽象的で簡潔なコードを書ける
* 状態変化の追放: バグを減らし、テストしやすくする

そして、Pythonで実用的関数型プログラミングを行う上で避けるべき三つのアンチパターンを紹介します。
一つ目、「長い式、複雑なlambdaを書く」。他の言語における関数型の書き方をまねようとすると、高階関数をずらずら連ね、複雑なラムダ式を書くことになりがちです。ですがPythonは、式の改行がしづらく、ラムダ式も煩雑な言語です。PEP8による一行の文字数制限も厳しいです。むしろ、式は適切に区切り、ラムダ式はローカル関数にして、説明的な名前をつけるとPythonらしいでしょう。
二つ目、「map/filterを多用する」。状態変化なしにコレクション処理を行おうとしたとき、一般的な言語ではmap/filter等を使いますが、Pythonではこの限りではありません。Pythonでは普通内包表記を多用します。イニシャライザにイテレータを取れば自作クラスでも内包表記に近い書き方ができますし、ローカル関数と組み合わせれば複雑な内包もシンプルに書けます。
三つ目、「内包やreduceを濫用する」。Pythonで関数型のプログラムを書こうとして、複雑なreduceや内包表記を書くと読みづらくなりがちです。Guidoもreduceより、状態変化を含むforループを好んでいました。たとえ状態変化を含んではいても、コードを関数に切り出し、変化を隠蔽できれば、実質的には関数型プログラミングと同じであり、可読性も高まります。
四つ目、「クロージャを濫用する」。関数型スタイルにおいては、しばしばクロージャを返す高階関数を使います。ただしPythonにおいては、クラス定義によってほぼ同じ機能を実現できます。オブジェクト指向に慣れた人には、むしろそちらの方が読みやすいでしょう。チームメンバーの好みと相談しつつ、状態変化があったり一定程度複雑な場合はクラス定義に書き換えるといいでしょう。

構成とタイムラインは以下です。

* 導入(5分)
  - 自己紹介
  - 問題設定
* 関数型プログラミングの定義(5分)
  - 高階関数の多用
  - 状態変化の追放
* アンチパターン1: 長い式、複雑なlambdaを書く(3分)
  - アンチパターンの例
  - 長い式がPythonっぽくない理由
  - 式を区切り名付ける
* アンチパターン2: map/filterを多用する(5分)
  - アンチパターンの例
  - 内包表記を使う例
  - 独自クラスで内包表記っぽく書く
  - ローカル関数と組み合わせる
  - map/filterが便利なケース
* アンチパターン3: 内包やreduceを濫用する(4分)
  - アンチパターンの例
  - 状態変化+forを関数に隠蔽する
  - 関数に切り出せば状態変化も問題ない
* アンチパターン4: クロージャを濫用する(5分)
  - アンチパターンの例
  - オブジェクトに書き換える
  - \_\_call\_\_を使う
  - 使い分けを考える
* まとめ(1分)
* 質疑応答(2分)",佑京 鈴木,株式会社ピコラボにて受託研究開発に従事するプログラマ。
203756,Django + SQLAlchemy: シンプルWay,#pyconjp_3,1,3,DjangoのORMはとても便利です。しかし、SQLならすぐに書ける「サブクエリをINNER JOINする」「1つのテーブルを2回OUTER JOINする」といったクエリをDjango ORMで表現するのは苦手です。生のSQLを書いてDjangoで実行する方法もありますが、動的にSQLを組み替えるのが難しくなったりSQL Injectionのリスクもあるためお勧めできません。SQLAlchemyを使えば、この問題を解決できます。このトークでは、SQLAlchemyでSQLの組み立てる方法と、Django上で安全に実行する方法について紹介します。,"Django ORM, SQL",SQLAlchemyの使い方、Djangoとうまく組み合わせて使う方法,Talk(30min),Intermediate,50%,Web programming (including web frameworks),Japanese,Both,"DjangoのORMはとても便利ですが、少し複雑なクエリを組み立てようとすると急に難しくなってしまうことがあります。例えば、サブクエリの結果をINNER JOINしたい場合や、1つのテーブルを2回OUTER JOINしたい場合などは、SQLならすぐに書けるのにDjango ORMで表現するのがとても難しかったり、不可能だったりします。このような場合にSQLを直接書いて `Model.objects.raw()` や `execute()` で実行する方法もありますが、この方法では動的にSQLを組み替えるのが難しくなったりSQL Injectionのリスクもあります。
このトークでは、SQLAlchemyをSQL表現言語として使う事でSQLの組み立てをプログラムで行い、Django上で安全に実行する方法を紹介します。

アジェンダ

* Django ORMで表現が難しいSQLの例
* SQLを直接書いてrawやexecuteで実行する例と問題点
* SQLAlchemyの紹介と簡単な実行例
* 複雑なSQLをSQLAlchemyで組み立てる
* SQLAlchemyとDjangoの連携
",shimizukawa,"BeProud所属。一般社団法人PyCon JP 会計理事。2003年からPythonを使い始め、Python mini Hack-a-thonなどPython関連イベント運営のかたわら、国内外のカンファレンスへ登壇しPython技術情報を発信するなど、公私ともにPythonとその関連技術の普及活動を行っている。最近Drone飛ばし始めました。
著書／訳書：『自走プログラマー（2020年 技術評論社刊）』『Pythonプロフェッショナルプログラミング第3版（2018 秀和システム刊）』『エキスパートPythonプログラミング 改訂2版（2018 アスキードワンゴ刊）』『独学プログラマー（2018 アスキードワンゴ刊）』『Sphinxをはじめよう第2版（2017 オライリー・ジャパン刊）』。
"
203309,I can't believe it's still here!,#pyconjp_4,1,3,"""I can't believe this piece of code is still here!""

You may shout it out when you see a function should have been deprecated in 3 years ago. The function may be created by your ex-colleagues but no one manages it after his / her leave. It may hit the system now, or just silently stay in the great number of source files. You may still ponder the next move - remove it now, or let it stay there until the application retirement. The talk will dives into this scenario and purpose a systematic approach, [auto-deprecator](https://github.com/auto-deprecator/auto-deprecator), to resolve the problem.",No prerequisite is required.,"- The target audience are those who cares about software quality, ranging from open source project contributors to enterprise application product owner. 

- The audience can have a high level view on removing a dead code without much effort.",Talk(30min),Beginner,0%,Tips of development with Python,English,English only,"### Introduction (2 mins)

### Case study (3 mins)

The introduction is a case study of Knight Capital Group incident in 2012. The incident was a major stock market disruption caused by the group and led to a huge trading loss in the firm. The root cause was an expired application called Power Peg accidentally running after the market open, and the application was running for 45 minutes until the team discovered and shut it down. The case is a good example to illustrate how a technical debt of unused codes can turn into a financial debt in a company.

### Analysis (5 mins)

Most developers are smart and passionate in programming, but why do they tend to keep a dead source code in the project? 

First the following myths will be deserted in the talk.

Myth:

- Lack of diligence and attitude

- Lack of incentive

- Lack of development time and resource

Then the following reasons will be gone through

- Uncertainty and indefinite business value to clean technical debt

- Unclear usage from the clients and downstream processes on the existing application

- Missing tools / systematic approach to remove unused codes

### Approach (7 mins)

The talk will separate the timeline to retire an unused function into three stages: Warning, Expired and Cleaning.

1. Warning

The stage requires to alert the developers and users the future deprecation of the code. If the piece of code is used in the closed system, the developers should head up the team on it. The easiest way is to put the concerned developer into the pull requests to review. A message, an email, or a release notes is also an appropriate approach.

If it is public for the users or the depending systems, it can first give a deprecation warning when it is called. The product owner should also plan ahead the expiry version and execute it in the future. Finally, a conversation with the potentially impacted clients is a direct approach.

Also, releasing the software with versions aligned with [SemVer 2.0](https://semver.org/) can give a big hints for the users of choosing a proper version to install.

2. Expired

In the expired stage, the user should get an exception when the deprecated function is called. In the interactive usage, the user migrate the deprecated function to the suggested one in the exception message. For the downstream process, if its developers are not aware of the deprecation plan before the expired stage, they can still work around the exception with a specified handling, e.g. injecting environment variable.

3. Cleaning

After the expired stage, the deprecated function should be removed from the code base. It is easy to execute, but also easy to forget the execution in the stage. If it requires the manual effort to proceed this process, the team has to strive a good balance on the deprecation frequency. For example, in pandas, the deprecations will only be enforced in major releases, so that the team can focus on functionity enhancement and bug fix in the minor versions.

### Auto deprecator (5 mins)

The library [auto-deprecator](https://github.com/auto-deprecator/auto-deprecator) will be introduced as a systematic approach to the approach mentioned before. The section will go though some code examples about how the library can tackle the problem pragmatically. I will also compare the library `auto-deprecator` with other open source libraries, e.g. [deprecated](https://github.com/tantale/deprecated) 

1. Warning

Developer can put a Python decorator on the function or class method to warn the users the expiry version and migrated function name. To customize the handling method to align with the team practice, the default warning behavior, i.e. throwing `DeprecatedWarning`, can be modified.

Meanwhile, the downstream processes can test the impact of the deprecated function by injecting the environment variable `DEPRECATED_VERSION`.

2. Expired

The nightmare for the developers is once the function is deprecated, the clients or the developers of the downstream processes call in and ask back the function. They may not be aware of the deprecation schedule, or they do not have sufficient development resource to handle it in time. The environment variable `DEPRECATED_VERSION` is the last safeguard to this situation.

3. Cleaning

The script `auto-deprecate` in the library can be added in the continuous integration / continuous delivery flow. Before releasing the package, the script removes all the expired source codes, and run all the unit test cases. It saves the development time to manually execute the code removal in a systematic approach.

### Conclusion (3 mins)

### Q&A (5 mins)",Gavin Chan,Gavin Chan is a principal quantitative developer in AXA Investment Managers Chorus Ltd with 7+ years of experience in software development and finance industry.
203588,Python × AWS × Serverless 初学者が次の一歩を踏み出すためのテクニック,#pyconjp_2,1,3,"サーバーレスが界隈でホットな話題になってゆくなか、初学者であった私は興味を持ちつつも中々チュートリアルの次に進めずにいました。入門編の次の一歩を踏み出すための情報源が少なく、何から始めたらよいのかがわからなかったのです。この状況は私が観測する限り現在も続いており、多くの初学者が同じ悩みを持っているのではないかと思います。

私が業務経験やプライベートの開発において得た知見の一部を紹介することで、以前までの私と同様の悩みを抱えていたエンジニアの助けになればと思います。","[1] デコレータに関する知識
自力で実装できる必要はないが、どのようなものであるかは知っていること。
ロギング周辺の話題で扱います。

[2] AWS Lambda に関する知識
資料等で概要を知っているのであれば、それでも構いません。
Hello world レベルでも、経験があると望ましいです。
IAM等の周辺知識は不要です。

[3] Serverless Framework もしくはそれに類するフレームワーク(※)の利用経験
デプロイまでのチュートリアル程度の経験があると望ましいです。
しかし、冒頭に簡単に説明はするので必須ではないと考えています。
(※) ... AWS SAM, Terraform, Zappa など
","・サーバーレス開発におけるプロジェクト構成
・ローカルとクラウドの両方で動作する、開発やすいコードのあり方
・運用時に役に立つロガーの作り方",Talk(30min),Intermediate,50%,Case studies (excluding web programming or machine learning),Japanese,Japanese only,"Serverless Framework が普及したことで、サーバーレス開発を取り巻く環境は大きく進化しました。ごく簡単なボットアプリケーションやAPIサービスであれば、極めて短時間で自身のコードをデプロイすることができます。

しかし、そのような入門体験を終えた後、次の足場を見失ってしまう初学者も多いのではないかと思います。ひとつの理由は、サーバーレス開発におけるイディオム、あるいはプラクティスと呼べる情報源が比較的少ないことにひとつの理由があるのではないかと、私は考えています。

そこで、このセッションでは発表者が業務で得た知見を交えつつ、サーバーレス開発をより豊かにするノウハウをご紹介します。
構成とタイムラインは以下の通りです。

・導入 (2min)
　・自己紹介
　・本発表のモチベーション
・AWSにおけるサーバーレスアプリケーション構築の基本 (3min)
　・イベント駆動アーキテクチャへのシフト
・Serverless Framework 基本のおさらい (3min)
　・Hello world / プロジェクト作成からLambda Function のデプロイまで
・プロジェクト構成の一例 (5min)
・python-dotenv と serverless-dotenv-plugin の活用 (7min)
　・ステージごとの変数管理
　・ローカルとクラウドの両方で動作するコード
・ロギングのプラクティス (7min)
　・トレース可能なIDを付与する
　・JSONロガーを用意する
　・ハンドラ関数にロギング用デコレータをアタッチする
・まとめ (1min)
・質疑 (2min)",hassaku,"株式会社サーバーワークス所属。ここ1年ほど、MSP（マネージド・サービス・プロバイダ）事業に関わるプロダクトの保守と開発をやっています。

技術同人誌「実践 AWS CDK - TypeScript でインフラもアプリも！ (技術書典9 出典作品)」の共同著者です。
https://booth.pm/ja/items/1881928"
203453,PythonでXBRL形式の財務情報を扱おう,#pyconjp_5,1,3,"コロナ禍に見舞われた今年、上場企業の財務状況の変化に興味を持つ方が増えているのではないでしょうか。
このトークでは、Python製OSSであるArelleを利用し、XBRL形式の有価証券報告書から欲しい情報を取得する方法を共有します。","- 何らかのパッケージを使ってPythonでスクリプトを書いた経験。
- XML形式のデータを解析したこと、財務諸表を読んだことがあるとトークがより理解しやすいですが、必須ではありません。","- Python製OSS Arelleの使い方
- XBRLの基礎知識
- 金融庁EDINETから有価証券報告書などのデータを取得する方法",Talk(30min),Intermediate,0%,Data Science / Machine Learning,Japanese,Japanese only,"XBRLとは、各種事業報告用の情報を作成・流通・利用できるように標準化されたXMLベースの言語です。
日本では上場企業などに対し、有価証券報告書などの書類をXBRL形式で提出することを（原則）義務付けており、そのデータは金融庁のEDINETという電子開示システムで公開されています。

1社の過去数年の実績推移や2社比較などを行う場合は、無償公開されている分析用サービスを利用すると手間が掛からず便利でしょう。  
しかし、ある業種の企業全体をまとめて扱ったり公開サービスで提供されていない分析を行ったりしたいケースもあると思います。そのような時には自分で必要なデータを作成する必要があります。

そのデータの作成方法と、必要な前提知識をこのトークで紹介します。  
  
XBRLの解析には Arelle というPython製のOSSを使用します。Arelle は XBRL International というXBRLを開発・保守する組織により、XBRL仕様に準拠したレポート使用ソフトウェアとして認定されています。  
Arelleを活用することで仕様の複雑なXBRLの解析が楽になります。  
しかし、その使い方が分かる情報は現状では少ないです。  
このトークでは、上記のデータ作成例を通して、Arelleの主要な機能の使い方も紹介していきます。
 
処理対象として、EDINETで公開されている上場企業の有価証券報告書（または四半期報告書）を使用します。  
財務分析はトーク対象外です。  

構成とタイムラインは以下のとおりです。  
※多少変更する可能性があります

+ 導入 (2min)
　- 自己紹介
　- きっかけ

+ XBRL (4min)
　- XBRLとは
　- 基本構造
　　- タクソノミ
　　- インスタンス

+ EDINET (4min)
　- EDINETとは
　- EDINETタクソノミ
　- 提出者別タクソノミ
　- 必須項目

+ Python製OSS: Arelle (3min)
　- Arelleとは
　- ArelleでXBRLを解析するメリット

+ 財務三表の概要 (3min)

+ 複数企業の財務データをまとめて扱う際の注意点 (2min)

+ PythonでXBRL形式の有価証券報告書を扱おう (10min)
　- EDINETからデータ取得（EDINET API）
　- XBRLデータから欲しい情報を取得（Arelle）
　　- 会社情報、提出書類情報
　　- 財務情報
　- 出力

+ まとめ (1min)
+ 質疑応答 (1min)",Miyasaka Eriko,経理歴3年、現在はデータ分析系の業務と趣味でPythonを使っています。
203925,Exploring Biasness in Indian Media,#pyconjp_5,1,4,"Recognition of bias in Indian Media poses a serious challenge due to the existence of various regional languages, political parties and huge population with different mindsets. I addressed this by finding out the kind of stories selected by media and find out the ideology that it promotes.",Target audience having introduction about ML methods would be great but it is not necessary.,"After watching this talk, audience will get to know about Topic Modelling and how to solve a unsupervised learning problem statement. This talk mainly covers the approach we took from the ground up which will be beneficial for beginners. ",Talk(30min),Intermediate,0%,Data Science / Machine Learning,English,English only,"                                            Introduction
We will discuss what is Biasness and why is it important. We will also discuss with some examples from India Media context to get a brief about data.
                                            
                                                Basics
We will mainly discuss about Topic Modelling and go brief on Latent Dirichlet Allocation Algorithm. We will implement LDA using gensim.models.ldamodel.

                                            Methodology
We will go over how we approached Biasness for Indian Media Context. All our experiments in this project were carried out using Python and it's different libraries. 

In the end we will talk about the results and takeaway from the project.

Outline:
1. Intro to Bias and Types of Bias [5 Min]
2. Brief about Indian media and Dataset Introduction[2 Min]
3. Into to Topic Modelling [3 Min]
4. Approach Outline[10 Min]
    * Why we used latent dirichlet allocation and Demo
    * Our Methodology
5. Takeaways and What does the results signify?[5 Min]
6. Q&A [5 Min]",prashant0598,"Prashant is a distinguished full-stack data scientist, skilled in application of machine learning techniques for solving data based problems. Currently, a final year undergraduate Computer Science student and also a Data Science Intern at Guavus . He is an experienced open source developer and have also mentored for SCoRE Lab. He began his career as Data Science Intern at PwC where he worked with Logistics client to automate their internal process and drive sales .

Prashant is Co-Organiser of Local Python Community group called PyJaipur, which is largest technical group in that state. He is an active community guy and loves to share and learn as much he can by organizing Meetup and networking with individuals."
203875,GAE/Python2 to Python3 Migration Journey,#pyconjp_2,1,4,本セッションでは、Google App Engine (GAE) の Python 2.7 で構築されたアプリケーションを、 Python 3.7 基盤に移行していく際の戦略・戦術についてお話します。GAE/Python2とPython3は、基盤の設計思想が大きく異なるため、単なる言語バージョン更新ではなく、アプリケーションの根幹となるライブラリ・アーキテクチャの刷新が必要なプロジェクトです。APIエンドポイントが300個ほどあるアプリケーションを、安定稼働させながら順次移行していくために編み出した戦術・戦略についてお話します。,Webアプリケーション開発を行った経験がある,大規模なアプリケーション・アーキテクチャの変更を、安全・確実に進めるためのナレッジ,Talk(30min),Intermediate,0%,Web programming (including web frameworks),Japanese,Japanese only,"本セッションでは、Google App Engine の第一世代ランタイムである Python 2.7 で構築されたアプリケーションを、第二世代ランタイムである Python 3.7 に移行していく際の戦略・戦術についてお話します。

Google App Engine (GAE) は、 Google が提供するWebアプリケーション実行基盤です。 GAEそのものは、Google Cloud ブランドが登場する以前の 2008年から提供されている歴史あるサービスです。
GAEの第一世代(Python2.7)と第二世代(Python3.7)の間では、アプリケーション構築のアプローチが大きく異なります。第一世代ランタイムでは、アプリケーション開発に必要となる多くの機能（データベース、非同期タスク、スケジューラ、全文検索、キャッシュ等）が AppEngine SDK に統合されており、対応するライブラリを import するだけで利用することができました。第二世代ランタイムでは、各機能に対応する後継のクラウドサービスを１つずつ自分で選択して組み込む形へと変化しました。

このように、GAE/Python2 から GAE/Python3 への移行は、単なる言語バージョンの更新プロジェクトではなく、アプリケーションの根幹となるライブラリ・アーキテクチャの刷新を必要とするプロジェクトです。私達の開発するアプリケーションは、300個近いAPIエンドポイントを持っており、これらを一度に全て切り替えることは困難です。安定稼働させながら、順次移行していくために編み出した以下のような戦術・戦略についてお話する予定です。

- API単位での部分移行戦略
- アプリケーション基盤ライブラリのギャップを埋めるための独自ライブラリ整備
- 型ヒント等を活用した堅いプログラミング
- 実データでの互換性チェック環境の構築
- など

構成・タイムライン
 - はじめに・自己紹介 - 5分
 - 背景 - 5分
 - GAE移行の戦略 - 7分
 - GAE移行の戦術 - 8分
 - まとめ - 5分
",Akira Yumiyama,株式会社レヴィ CTO として「変化に強いシステム設計」を広めるためサービス開発を行いつつ、技術顧問としても活動している
203941,Pythonで始める負荷試験,#pyconjp_4,1,4,"Webシステム運用時に避けては通れない工程のひとつに負荷試験があります
負荷試験に用いられるツールには様々なツールが存在しますが、
どのツールを用いても以下のようなことに直面するのではないでしょうか？

複雑なシナリオを書かざるを得ない状況
アプリケーションの更新に合わせてシナリオも更新しなくてはいけない状況
チームメンバーへシナリオを共有しなくてはいけない状況
様々な境界値や条件を指定してテストをしなくてはいけない状況
テスト結果を共有しなくてはいけない状況

これらに対してPythonを用いてチーム開発の現場で取り組んだ内容を、
実例を元にデモを交えてご紹介させて頂きます","Pythonを用いてwebアプリケーションを作成した経験
負荷試験を行った経験があるとより理解が深まると思いますがMUSTではありません","・Pythonを用いて負荷試験を行う方法
・Locustの操作方法
・負荷試験手法ならびに結果を俗人化させない方法",Talk(30min),Intermediate,0%,Tips of development with Python,Japanese,Japanese only,"JMeterやGatlingなど負荷試験では様々なツールが用いられています
しかし、Locustを用いた負荷試験の実例は他ツールに比べて数が少ないのが現状です
また、Webシステムに対して負荷試験を行う際に直面する「複雑なシナリオ作成」・「境界値の変更」だけでなく
チームメンバーへの「シナリオの共有」・「結果の共有」をどのように実現したか
実際の事例を元に本発表でお伝えさせて頂ければと思います
構成とタイムラインは以下のとおりです
- 自己紹介(1分)
- Locustの紹介(5分)
  - インストール方法
  - シナリオの書き方・起動の仕方
- 活用方法(10分)
  - なぜLocustを使おうとしたか
    - 他のツールとの比較検討
  - 負荷試験実施
    - 境界値の変え方
    - テスト条件変更方法
    - シナリオの更新・共有
    - テスト結果の共有
  - どんなメリット・デメリットがあったか
- デモンストレーション(10分)
- まとめ(3分)
- 質疑応答(1分)",Yusuke Nishio,"株式会社ブレインパッド,Webアプリケーションエンジニア
リスティング広告運用自動化ツールの開発に従事"
201618,What happens behind execution of an `import` statement?,#pyconjp_1,1,4,"Have you ever spent 10-15 minutes debugging ImportErrors, ModuleNotFoundErrors, without reaching anywhere? Would you want to learn about what happens from the moment Python parses 'import x', to the point when you execute a function of 'x' module? Let's dig into the internals of the Python's import system.","Syntactic knowledge of Python
Should have come across import/$PYTHONPATH related errors
If you don't know either and still like the talk idea, please follow [this](https://gist.github.com/plant99/9fee5dbe73f25d4da9c7fb956a36b889) gist to 'intentionally' come across the errors :)","An understanding of the import system's mechanics, which helps to quickly debug and fix path/import related errors.
Knowledge of import hooks, to build custom import related plugins.
",Talk(30min),Beginner,0%,Python core,English,English only,"TL;DR

This talk follows this template to explain what goes on in the background when you execute from spam import ham, or any other import statement. Additionally, it discusses import hooks and how use them.


Introduction

Every Python script involves import statements. And if you develop software with Python, you might already have come across import and path related errors like ImportError, ModuleNotFoundError, etc.
It's important to know the import mechanics, both for general knowledge, and to develop custom plugins to tweak the import system. In this talk, we'd discuss in detail about how the import system works, its components and what tasks they perform respectively.


Who should attend this talk?

This talk is most suitable for beginner to intermediate level Pythonistas.


How does the talk proceed?

- The talk starts with packages in Python, and how to organize Python files in order to make them distributable, and importable.
It proceeds to discuss about $PATH and $PYTHONPATH, and how they are used to enable system-wide imports, and how capable are Python's path based import handlers, if they let a programmer import from remote URIs, etc.
- Different types of packages such as regular packages, namespace packages, frozen modules, etc. are discussed.
- After that, some key components are introduced i.e sys.modules and how modules are refreshed and regulated in runtime, what finders and loaders are, and what 'import protocol' is, sys.meta_path, sys.path_hooks
- The talk then goes in detail about finders, the default finders in Python, spec object, and its functioning.
- After finders, loaders are discussed with sample code, explaining the steps involved from processing a spec, and creating, executing, and loading a module to sys.modules.
- After finders and loaders, 'import hooks' are discussed i.e how Python allows injection of custom components to handle a pre-defined import statement.
- This follows a demonstration of import hooks, implementation of a meta_path finder Class which protects importing of modules from an http server with a token exchange. (So the source code is protected, and it can be logged who requested the source code by a signature to act against misuse.)
- The demonstration is followed by listing some important use cases of import hooks, and how folks have used it in the past.


What can someone get out of this talk?

An understanding of the import system's mechanics, which helps to quickly debug and fix path/import related errors.
Knowledge of import hooks, to build custom import related plugins.


Outline

Time Duration - Topic

0 - 4 Introduction to packages and how to organize packages

4 - 7 Types of packages in python, and the default ones the import system supports.

7 - 12 Components of import system - sys.modules - finders and loaders - chronology of import related tasks

12 - 15 Finders, examples of finders, and how they function, find_spec function

15 - 17 sys.meta_path, sys.path_hooks in detail

17 - 19 Introduction to PEP 302, and import hooks

19 - 22 explain loaders with template code

23 - 25 code walkthrough and demonstration of an implementation of import hooks

25 - 26 briefly cover 'importing of submodules' topic with an example

26 - 28 present use-cases of import hooks, and usage in industry, conclude.

28 - 30 Q&A",Shivashis,"Shivashis Padhi is a senior, majoring Computer Science and Engineering at National Institute of Technology, Tiruchirappalli, India.

He loves earth and atmospheric sciences and pursues them as hobby. With a desire to contribute more directly towards research in these areas, he has developed a keen interest in Geographic Information Systems over time.

With ~3 years of experience as a student software developer associated with a multitude of student organization(Python Software Foundation - GSoC'20, Delta Force), small and large scale startups(Grofers, Flytbase Labs, Gmetri), he lives by a simple policy, 'learn and build to make the world a better place'."
202389,量子コンピュータと現行コンピュータ、解法や解の違いは？～ナップサック問題を考える～,#pyconjp_3,1,4,"Pythonを使用し、注目を集める最先端の量子コンピューティング技術を取り扱います。
量子コンピューティングの中でも特に量子アニーリングを使用し、組合せ最適化問題に取り組みます。組合せ最適化問題の一つであるナップサック問題を例題に取り上げ、量子コンピューティングフレームワークのBlueqatで解を求めます。
またこれに並行して、現行のコンピュータを使用した組み合わせ最適化問題の一般的な計算ツールであるGoogle OR-ToolsソルバーをPythonでプログラミングし、解を求めます。
組合せ最適化問題について知るとともに、その解法として量子アニーリングや汎用ソルバー、それぞれのプログラミング手法とその実行結果を学び、検証します。",必須ではありませんが、量子アニーリングやナップサック問題が何かを知っていると理解しやすくなります。,量子アニーリングと組合せ最適化の関係、ナップサック問題の解法、BlueqatやOR-Toolsの使い方など,Talk(30min),Intermediate,50%,Data Science / Machine Learning,Japanese,Japanese only,"Pythonを使用して量子コンピューティングを取り扱います。今、最も注目を集める最先端技術の一つとして、量子コンピューターがあげられます。今回は、特にその機能の一つである量子アニーリングを取り上げ、組合せ最適化問題を解きます。

量子アニーリングは組合せ最適化問題に特化した量子コンピューティング技術です。量子アニーリングを実行するにあたり、MDR社(東京)からオープンソースで提供されているBlueqat(ブルーキャット)を使用します。BlueqatはPythonで動作する量子コンピューティング専用のフレームワークです。

組合せ最適化問題とは、ある課題を解決する際に、その構成要素に対して、選択する／選択しないや、数量を超えない、最大値／最小値を求める、等の条件のもとで最良の解を求める問題で、工場の生産計画や勤務シフトスケジュール、物流配送など幅広い分野でビジネス課題として取り組まれています。この組合せ最適化問題の中でも特に基本的な問題であるナップサック問題を例題に取り上げ、最適解を求めます。

量子コンピューティングの一方で、現行のコンピュータ上でアルゴリズムを組み、解を計算し最適解を求める取り組みも盛んに行われています。このような最適化問題を解くための専用ソフトウェアとして、ソルバーと呼ばれるツールが多数開発されています。今回は、これらの中からGoogle社によりフリーで提供されているGoogle OR-Toolsを使用して、同じナップサック問題を解きます。Google OR-ToolsはPythonでプログラミングするソルバーです。

最後に、量子アニーリングにより算出した解と、ソルバーにより算出した解を比較し、結果を検証します。

今回の取り組みを通して、組合せ最適化問題について知るとともに、その解法として量子アニーリングや汎用ソルバーがあること、またそれぞれのPythonによるプログラミングと解の算出の仕方、さらにそれぞれの解の結果について学ぶことができればと思います。

＜主な流れ＞

1.今回の取り組みの概要
2.組合せ最適化問題とナップサック問題について
3.量子コンピュータと量子アニーリングについて
4.Blueqatによる量子アニーリング解法
5.現行コンピュータと汎用ソルバーについて
6.Google OR-Toolsによる解法
7.両者の解の比較検証とまとめ",哲朗 田端,システムエンジニアとして金融や通信など様々な分野のシステム開発に携わっています。
203956,Combining ayncio and threads in the same application,#pyconjp_3,1,5,"In recent years, the asyncio environment in Python has matured a lot. Something which is often considered an issue, though, is combining code which does not support asynchronous execution with otherwise async code. The talk will show that this is not really a major problem anymore and can indeed be used to bring blocking code or threaded code into the async world as well.","Some knowledge about asyncio and threading would be useful, but is not essential.","The talk will show that combining async and threaded code is not really a major problem anymore, allowing you to use both in your applications.",Talk(30min),Intermediate,50%,Case studies (excluding web programming or machine learning),English,English only,"Subtitle: Writing a Discord bot which streams YouTube videos to channels

In recent years, the asyncio environment in Python has matured a lot. Something which is often considered an issue, though, is combining code which does not support asynchronous execution with otherwise async code. The talk will show that this is not really a major problem anymore and can indeed be used to bring blocking code or threaded code into the async world as well.

The practical example is a Discord bot implementation, which uses asyncio for handling requests, with a threaded application using the VLC to create snapshots of YouTube live streams at regular intervals. The snapshots are then sent to a Discord channel to give a preview of the various talk sessions held online. We will use this bot at EuroPython 2020 on our Discord server.",Marc-Andre Lemburg,"Marc-Andre is the CEO and founder of eGenix.com, a Python-focused project and consulting company based in Germany. He has a degree in mathematics from the University of Düsseldorf.

His work with and for Python started in 1994. In 1997, he became a Python Core Developer. He designed and implemented the Unicode support in Python and continued to maintain the Python Unicode implementation for more than a decade, after it first appeared in Python 2.0. He also authored the well-known mx Extensions, e.g. mxTextTools, mxDateTime and mxODBC, which are now distributed and maintained through eGenix.com.

Marc-Andre currently is Chair of the EuroPython Society (EPS) which organizes the EuroPython conference series and support the Python community in Europe.

He is also a founding member and Fellow of the Python Software Foundation (PSF) and has served on the PSF Board several times.

Today, Marc-Andre spends most of his time consulting and managing large-scale customer projects heavily relying on Python and databases. More details are available on http://www.malemburg.com/."
203444,PySnooper - Never use print for debugging again,#pyconjp_1,1,5,"I had an idea for a debugging solution for Python that doesn't require complicated configuration like PyCharm. I released PySnooper as a cute little open-source project that does that, and to my surprise, it became a huge hit overnight, hitting the top of Hacker News, r/python and GitHub trending. In this talk I'll go into:

 * How PySnooper can help you debug your code.
 * How you can write your own debugging / code intelligence tools.
 * How to make your open-source project go viral.
 * How to use PuDB, another debugging solution, to find bugs in your code.
 * A PEP idea for making debuggers easier to debug.",Basic Python development," * Learn how to use PySnooper to debug your code
 * Learn how to use PuDB to debug your code
 * Learn how to communicate your open-source project to others",Talk(30min),Intermediate,50%,Tips of development with Python,English,English only,A new debugging solution for Python that became a huge hit overnight,Ram Rachum,"Ram Rachum is a software developer specializing in Python. When he's not writing his biography in the third person, he's doing consulting work for clients big and small, giving Python training to teams that would like to deepen their Python skills, and organizing the bi-monthly PyWeb-IL conference.

Python training: http://pythonworkshops.co/"
203877,Pythonソースコードの構造可視化とそれがもたらすもの,#pyconjp_2,1,5,"1万行を超えるようなアプリケーションの開発に途中からジョインしたとき、最初に何をしますか？
コードの全体像が分からなくて困ったことはないでしょうか。
このトークではそういった場面で役に立つ、Pythonコードの依存関係を明らかにするツールを紹介します。
このツールを作るきっかけや、このツールによって何が明らかにできるかを紹介し、それがソフトウェア開発の中でどのように役立てられるか、についてお話ししたいと思います。",Pythonを使ってアプリケーション開発を行った経験がある,Pythonアプリケーションコードの全体像を捉える方法とその意味や活かし方。,Talk(30min),Intermediate,0%,Tips of development with Python,Japanese,Japanese only,"このセッションではPythonコードの構造（パッケージ間の依存関係など）を可視化するツール（jig-py）についてお話しします。
新しくプロジェクトに参加し全体像を素早く把握したい場合や、コードのアーキテクチャを見直す場合に、全体の関係性を俯瞰して見ることが役に立ちます。

## 背景

このツールを作るきっかけとして、500以上のPythonファイルで構成されるアプリケーションのPython2/3移行プロジェクトに参加しました。アプリケーション基盤の都合でPython2アプリケーションの一部を切り出して、新たなPython 3アプリケーションを作成し、置き換えていく必要がありました。

最初に移行するべき対象を見つけ出すため、簡易的なスクリプトで各パッケージ間の依存関係を明らかにしました。それにより最初に手をつけるべき対象を見いだすことができ、無事プロジェクトを進めることができました。

さらに、実際に可視化して見ると循環参照のような望ましくない構造や、依存が多すぎるモジュールなど改善に生かす手がかりが得られることにも気づきました。

これがこのツールとして作っていこうと思ったきっかけです。

## jig-py について

Javaにはjigという素晴らしい可視化ツールがあり、そちらを参考にjig-pyというツールを作成しています。jig-py では以下の情報が分かりやすく把握できることを目指しています。


・パッケージ同士の依存関係
 　・パッケージ階層レベルに応じたグルーピング
・クラス同士の依存関係

## 可視化がなぜ重要か

ソフトウェア開発は単純な作業ではなく複雑なプロジェクトです。そして、プロジェクトをゴールに向かわせるためには、次に何をすべきかを示す戦略が重要です。さらに、有効な戦略を立てるためには現状を正しく把握することが欠かせません。

これが、なぜ可視化することが重要か、の答えになります。

パッケージやクラスといった大きい単位で構造を明らかにすることで、コード1行1行の詳細度では追うことのできない大きなレベルでの戦略を立てることができるようになります。

例えば、

・健全/不健全な構造の把握
・変更リスクの高いデンジャーゾーンの把握

これにより、テスト戦略や、次期機能開発の生産性向上のための改善領域選び、新人の適切なアサイン領域選びなど、建設的な意思決定が行えるようになります。

そして、それを複数の人、チームでの共通認識として認識できるようになることも重要です。
定点観測し、活動のフィードバックとして利用することで、組織的にも前進させることができるようになります。


構成とタイムラインは以下の通りです。

・導入（1min）
　・自己紹介
・背景（3min）
　・jig-pyを作るに至ったきっかけ
　・名前の由来
・jig-pyの可視化によってわかること（12min）
・可視化がなぜ重要か（10min）
　・開発戦略
　・エンジニア組織の生産性、健全な文化づくり
・まとめ（2min）
　・発表内容のまとめ、今後の展望など
・質疑応答（2min）",yosu,LAPRAS所属。クローラー開発をメインにGAE/Python開発のお手伝いなども。
203963,Pythonではじめるソフトウェア無線,#pyconjp_4,1,5,"ソフトウェア無線を知っていますか？
ソフトウェア無線は無線通信に関わる処理の多くを、回路ではなくソフトウェアによる信号処理で実現したものです。

現在、安価なSDR受信機、OSSなSDR処理系やツールの登場によってソフトウェアエンジニアが電波の世界を覗き、さらには弄ることができる機会が飛躍的に増えています。そして、その中ではPythonが重要な役割を果たしています。

本セッションではUniversal Radio Hacker, GNURadio, Pothoswareの３つを紹介しつつ、それらの中でPythonがどう使われているか、そして活用方法として独自の処理やアプリケーション開発をするためのステップを解説します。

見えない電波が見えるの楽しいよ！",特にありません,"・ソフトウェア無線についての概略知識
・電波から無線通信プロトコルまでの処理・解析方法の概略知識
・Pythonを使ったソフトウェア無線アプリケーションの開発方法
",Talk(30min),Beginner,0%,Anything else basically which doesn’t fall into the types of topics above,Japanese,Japanese only,ソフトウェア無線(SDR - Software Defined Radio)の概要と応用例を紹介しつつ、各種実装の中で使われているPythonの用法と活用方法を解説します。,Taisuke Yamada,普段はJupyter NotebookでPythonをいじっている都内勤務のエンジニア。Pythonだとpython-ucdevをPyPIで公開中。気になる言語はJuliaとRust。この発表は完全に趣味です！
203110,スポーツデータを用いた特徴量エンジニアリングと野球選手の成績予測 - PythonとRを行ったり来たり,#pyconjp_5,1,5,"2001年以降のメジャーリーグの成績データを駆使して野球選手の成績予測をする, をテーマに

・スポーツデータを駆使した特徴量エンジニアリング
・統計的なアプローチを使った野球選手の成績予測
・PythonとRの使い分け・違い

をデータサイエンスという文脈で紹介します.","【MUST（最低限知っていて欲しい前提知識）】
・野球のルール. プロ野球や高校野球などをたまに楽しむぐらいのリテラシー（アウト・三振・四球・ヒットなど最低限のルールを知っている）.
・SQLやRを使ったデータ分析. 特に特徴量エンジニアリングや前処理の経験.

【あると良い ※任意】
・スポーツデータを扱った分析の経験
・マネーボールを読んだことがある","・分析・機械学習でやりたいタスクに合わせた特徴量エンジニアリングの勘どころ.
・特徴量エンジニアリングを行う際のPython/R/SQLの使い分け.
・PandasやplotlyなどのPyDataライブラリとGCP（BigQueryなど）を組み合わせたデータサイエンス環境のベストプラクティス.
・スポーツデータを用いたデータサイエンスの基本. ルール・記録のドメイン知識を特徴量までに持ってくるあたり.
",Talk(30min),Intermediate,50%,Data Science / Machine Learning,Japanese,Japanese only,"データサイエンスをする人々にとって, 生データを解析し分析可能な数値化を行う「特徴量エンジニアリング」「前処理」は必要不可欠かつ大切なタスクです.

その中でもスポーツデータサイエンスは特徴量エンジニアリング・前処理のやりがいがあるテーマであり, 中には「野球データサイエンスの応用で別の分野の分析に役立てる」というシグナルアンドノイズのような事例もあります.

この発表では, 「特徴量エンジニアリングの勘どころ」「野球選手の成績予測モデル作成と検証」を通じて, スポーツデータサイエンスのみならず, データサイエンス全般に役立つノウハウや知見を「野球の時間」を通じて紹介いたします.

Python周りだとPandasやplotly, データサイエンス関連だとBigQueryの知見が得られるかと思います.

【Outline】

- 自己紹介・野球の統計分析の基本（5min）
- 特徴量エンジニアリング #とは（10min）
　- 	生データの数値化
　- 泥臭い泥臭いアンド泥臭いタスクをシュッとこなす
　- Python/R/SQLを適切に使い分ける
- 野球選手の成績予測アルゴリズムとその実践（15min）
　- 第一人者のネイト・シルバーがやったモデル
　- shinyorke（わたし）がやろうとしているアプローチ
　- PythonとBigQueryでガツッと特徴量抽出
　- 分析そしてその結果は...!?
- まとめ

【補足】
2001〜2019年のメジャーリーグの公開データセットを元に予測を行います（日本のプロ野球ではありません）.",shinyorke,"株式会社JX通信社のシニアエンジニアで主にデータ基盤・SRE周りを担当.

個人としては, スタートアップの技術顧問としてデータ基盤に関するコンサルティングおよび, 「野生の野球データサイエンティスト」として野球データの分析や考察をブログ・登壇で発表しています.

Pythonは2011年からデータサイエンス・Webアプリケーション開発などなどで活用.

なお, 一部のPython使いから「野球の人」と呼ばれている模様."
202785,Python で作る演劇稽古用 Web アプリ,#pyconjp_2,1,6,"自分だけのアイデアを持っていても、何から手を付けてどう形にしたら良いか分からないといった経験を、多くの人が持って
いるのではないでしょうか。
そんな時、まず Python で出来ないかを考えてみるのも良いと思います。
このトークでは、スマホや Excel 向けに作ったアプリを Python で Web アプリとして作り直すことにした、私の心境を
お話しします。
アイデアを形にする時、Python という選択肢があることを知っていただければと思います。
また、機械学習で分類器をつくるのに、決定木のような気軽に試せるモデルがあることもご紹介します。","- Web アプリの基本的な概念。
- 機械学習の基本的な概念。","- アイデアを形にする時に、まずは Python で作ってみるという選択肢。
- Web Framework (Django) で、一人でどれくらいの物が作れるのかの目安。
- テキスト分類器のモデルに Deep Learning ではなく決定木を選んだ事例とその理由。",Talk(15min),Beginner,0%,Case studies (excluding web programming or machine learning),Japanese,Japanese only,"個人的に演劇稽古用 Web アプリの制作に取り組んでいます。
最初はスマホアプリとスプレッドシートで作っていたのですが、すべてを Python で作り直すことにしたので、その経緯と、
現在取り組んでいる課題をご紹介します。
根本的な発想は、台本をデータとしてフォーマット化し、稽古や制作のプロセスに利用するという事です。
最初にフォーマットを決めて、そのフォーマットを読み込んで表示するスマホ用の台本ビューアアプリを作りました。
その後、シーンごとの出番を抽出して稽古プランを立てるための Excel マクロを作りました。
しかし結局どちらもやめて、Python (+ Django) で、Web アプリとして作り直すことにしました。
前半ではその経緯についてお話しします。
後半では現在取り組んでいる、「適当に書いた台本をこのシステムのフォーマットに変換するツール」についてお話しします。
テキストを入力して「セリフ」や「ト書き」「柱」といった、「行の種類」を予測するモデルを作っています。
作者によって「どういうつもりで文書を整形しているか」が違うので、ファイルごとの特徴量と行ごとの特徴量を設計して、
決定木による分類をしています。
- 導入（2min）
    - 自己紹介
    - 私の個人プロジェクトについて
- プロジェクトのこれまでの経緯 (5min)
    - 昔の話#1: スマホアプリで台本ビューアを作った。
    - 昔の話#2: スプレッドシートで稽古プランツールを作った。
    - その後、Python のみで作ることにして設計し直した。
    - Web Framework (Django) を使って、すべて Web アプリにする事にした。
- 現在取り組んでいる課題（5min）
    - 台本をデータとして扱うには、決まったフォーマットになっている必要がある。
    - 自動でフォーマットするフォーマッタを作ろうとしている。
    - 行の種類 (セリフ, ト書き等) を予測するのに、Deep Learning は使わず具体的な特徴量を設計する事にした。
- 今後の課題 (1min)
    - Web アプリでありながらオフラインにも対応したビューアを作りたい。
- まとめ (1min)
- 質疑応答 (1min)",satamame,"- iOS アプリの開発 (実務 + 趣味)
- Android アプリの開発 (趣味)
- Django による Web アプリの開発 (実務 + 趣味)
- 演劇 (趣味)"
203793,Pythonで競プロをしよう！〜入門者が知っておくべき高速化Tips〜,#pyconjp_4,1,6,"最近AtCoderを中心に、競技プログラミングの人気が高まっています。
C++で参加している人が一番多いですが、Pythonで参加している人もかなり増えています。
Pythonは書きやすい一方でC++と比べてしまうと実行速度が遅く、Logicは正しくてもPythonだとTLE(Time Limited Exceeded, 時間超過)してしまうことも少なくありません。
しかし実際にはPythonでも高速化が可能で、ほぼ全ての問題がPython(/PyPy)でAC(Accepted, 正解)することができると知られています。
本セッションでは、Pythonで競技プログラミングをする際に把握しておくべき様々な高速化Tipsを紹介し、競技プログラミングにPythonで参加するハードルを少しでも下げることが目的です。","* 標準入出力の扱い、List/Dictといった基本的なデータ構造の利用経験といったPythonの基礎
* 競技プログラミングの概要
* AtCoderなどに実際にPythonで参加した経験があるとなおよい
","* Pythonでコードを書く際の高速化Tips
* 計算量に関する意識
",Talk(15min),Intermediate,50%,Tips of development with Python,Japanese,Japanese only,"基本的には各種Tipsを具体的に紹介していく形を考えています。
手元で実験した結果などを示しながら紹介をしていこうと考えています。


入力関連の高速化 (2min)
* `input`よりも`sys.stdin.readline`の方が早くなる話

Pythonの各種操作の計算量について (3min)
* list
* set/dict

再帰に関する話 (1min)
* `RecursionError`に注意しよう

ソートの速度について (2min)
* listのlistのソートはそもそも遅いが、`operator.itemgetter`を使うと早くなる話

PythonとPyPy (5min)
* Pyenvによる導入
* 両者の長所・短所
  * 「for/whileを多用している場合はPyPyにするだけで圧倒的に高速になるが、一方で再帰の場合はPythonの方が早い」など

質疑・応答(2min)",Kevinrobot34,"東京大学理学系研究科卒業後、株式会社ナウキャストに入社。
業務ではPythonを使いビッグデータの分析やデータ処理のためのパイプライン構築を行っている。
また趣味でPythonを使い競技プログラミングをしている。"
203665,オルタナティブデータを用いた消費行動の分析　～２月のトイレットペーパーパニックを例に～,#pyconjp_5,1,6,"新型コロナウィルス感染拡大は、私たちの日常生活や消費行動に大きな影響を与えている。感染防止に一定の効果があるとされるマスクだけでなく、トイレットペーパーといった日用品も極端な品薄となる現象も見られた。
このセッションでは、オルタナティブデータの一つであるPOSデータ（POSレジで商品が販売されたときに記録されるデータ）とPythonでのデータ分析や可視化ツールを用いて、新型コロナの影響で日本の消費行動がどのように変化したかについての細かい分析をしてみたい。
また、分析を通して、Pythonが提供する魅力的なデータサイエンティスト向けツールを紹介したい。具体的には、Shapely, Pandas, Plotly, Keplerを使う予定がある。
","Pandasでデータの読み込み方や基本的な扱い方
基本的な統計の知識
","Pandasの時系列分析の機能とShapelyの位置情報の機能
PlotlyやKeplerでデータの可視化する方法
データでストーリーを作り方
オルタナティブデータの知識",Talk(15min),Intermediate,50%,Data Science / Machine Learning,Japanese,Both,"1. 自己紹介
2. オルタナティブデータについて
3. 分析の事例（事例の解説、シンプルなコードの例、データの可視化）
 a)POSデータを使って、すぐに売り切れになった商品の種類を検知する。
 b)店舗の位置情報を用いて、売り切れになるまでのプロセスを調査する。
 例えば、ある店舗のマスクやトイレットペーパーが売り切れると、近隣店舗の販売にも影響するのだろうか？
 c) マスク価格と関連性のある要素を調査する。
例えば、店舗の所在地とマスク価格に関連性は見られるだろうか？
結論、質問",djentleman,"イギリス出身、東京在住のデータエンジニア/データサイエンティストです。
ポーツマス大学でコンピューターサイエンスを履修し、ロンドンにあるオルターナティブデータのベンチャー企業Huq Industriesで3年間働いた後、去年10月に来日してFintechベンチャー企業のナウキャストに入社しました。現在、オルターナティブデータを用いて投資家の意思決定を支援するプロダクトに取り組んでいます。"
203919,スタッフとしてコードを書こう！〜Code for PyCon JP and yourself〜,#pyconjp_3,1,6,"PyCon JP 2020のスタッフ活動で、私はPythonも書くことにしました。
手を動かすことで自身の成長につなげたかったからです。
コードを書いた結果、力がついたと感じるだけでなく、Pythonが代わりにやってくれるのでスタッフとしてできることも増えました。
私の取り組みを共有し、スタッフ活動もPython使いとしての成長の場となることを共有したいと思います。","PyCon JPのスタッフ活動についての知識は不要です。
Pythonの文法は理解していて、自動化やWebアプリ開発などに取り組んでいる方は、発表を聞いた後にPyCon JPスタッフ活動により興味を持っていただけるのではないかと考えています
（特に自動化レシピ本に取り組んだ経験やDjangoのチュートリアルに取り組んだ経験があると話がわかるでしょう）","・コミュニティへの活動の中でコードを書いた例（Googleスプレッドシートの読み取り、Slackへの投稿、DjangoでのWebアプリ開発）
・スタッフ＝コードを書いて自分の成長にもコミュニティにも貢献する機会という見方",Talk(15min),Intermediate,0%,Community building related to Python,Japanese,Japanese only,"この15分のトークでは、Python使いとしての成長を考える方がスタッフ活動の中でコードを書くヒントを提供します。
スタッフ活動はコミュニティに貢献する素晴らしい活動だと思いますが、その時間はコードを書けないというイメージもあるように感じます。
そんなことはなくて、スタッフもPython使いとして成長できる機会になると伝えたいです
（結果、2021は多くのスタッフがPythonの力を付けられたらいいなと思っています）

示す例は2つあります。

1. 通知の自動化の例
2. プロポーザルのレビューに使うWebアプリの開発

1はGoogleスプレッドシートを読み取り、集計したり条件に当てはまる行を抽出してSlackに通知するスクリプトです。
スプレッドシートのアクセスには`gspread`を使い、Slack投稿は標準ライブラリの`urllib`を使っています。
AWS Lambdaの関数にして、定期実行するように設定しています。

2はDjango製のWebアプリです。
プロポーザルの募集に使ったサービスのレビュー機能が使いにくかったため、手を動かして実装しました。
ログインはSlackアカウントで行います。
選択したプロポーザルを閲覧して、評価を入力できます。
プロポーザルを条件（例：英語／日本語）で絞り込む機能も実装しました。
プロポーザルの募集に使ったサイトからエクスポートしたデータをDjangoアプリに取り込む(loaddata)ために、JSONに変換するツールも作りました。

## タイムライン

- 自己紹介（1分）
- なぜコードを書くことにしたか（2分）
- 1 通知の自動化の紹介（5分）
- 2 レビュー用Webアプリの紹介（5分）
- まとめ 「スタッフとしてコードを書いて自分の成長にもつなげよう」（1分）
- 質疑（1分）",nikkie,PyCon JP staff (2019~)。2020はコンテンツチームリーダー。自然言語処理に取り組むデータサイエンティストでもある
203558,ラズパイ3BのCPUでリアルタイム物体検出,#pyconjp_1,1,6,"Raspberry Pi 3Bにカメラを繋ぎリアルタイムに物体検出を行うことを目指し、2年ほど開発を続けてきました。
現時点でNeural Compute Stickにも内臓GPUにも頼らず、CPU処理のみで11FPSのbounding box detectionを行えるようになっています。

このトークでは、実機でリアルタイム物体検出のデモを行った後、高速な物体検出を実現するために行ったことを
「検出モデル」「実行環境整備」の2つの観点から紹介します。
画像処理・物体検出を行っている方、Pythonでデータ処理を行っている方にとって、処理速度向上のヒントになれば幸いです。","必須ではありませんが
・Deep Learningによる画像認識を行ったことがあり、要求される計算量の多さを知っていること
・Raspberry Pi上でCPU性能を求められるアプリケーションを実行したことがあり、Raspberry Piの性能の低さを知っていること
・multiprocessingモジュールについての知識
の3点の知識があると、内容をより楽しめます。","・代表的な物体検出モデルの概要
・速度に特化した物体検出モデルの作り方
・精度向上に繋がるかもしれない、画像認識モデル学習上の工夫
・ONNX RuntimeをRaspberry Piに導入し、高速な推論を行う方法
・Python3.8で導入されたshared memoryを使用し、multiprocessingでのプロセス間のデータ受け渡しを高速化する方法",Talk(15min),Intermediate,0%,Embedding python in hardware,Japanese,Japanese only,"Raspberry Pi 3Bにカメラを繋ぎリアルタイムに物体検出を行うことを目指し、2年ほど開発を続けてきました。現時点では
1. カメラから画像を取得
2.「人」「動物」「乗り物」の3クラスを検出
3. 各クラスの位置を示す四角形を画像に追加し、ディスプレイに描画
が、CPU処理のみで11FPSで実行できるようになっています。
MobileNet SSDやTinyYOLOなどの軽量な物体検出モデルでも3FPSを下回ることを考えると、速度面だけを見れば非常に高速です。

高速化の試行錯誤を経て得た知見を「検出モデル」「実行環境整備」の2つの観点から紹介します。

■検出モデル
Deeplearningを用いた物体検出モデルであるYOLOをベースにネットワークを軽量・簡素化することで、より高速なモデルの作成を目指しました。
ネットワークを軽量化するとどうしても精度が下がりますが、少しでも精度悪化を緩和するために学習手法を試行錯誤し、
・既に知られている「学習が進んだらミニバッチサイズを大きくすると良い」を自動化する実装
・転移学習を繰り返し行うと精度が上がるという知見
を得ました。

■実行環境整備
検出モデルを軽量化することに加え、効率よく処理を実行できるよう
・モデルをonnxにexportし、高速な推論エンジンであるONNX Runtimeで推論を行う
・画像撮影と検出結果描画を検出とは別のプロセスで動作させ、最も時間のかかる検出処理がブロックされないようにする
としました。
プロセス間のデータ受け渡しはmultiprocessing.Queueを使うのが便利ですが、
SharedMemoryを使うことでQueueよりも高いFPSが得られることが分かりました。
また、Python3.8自体がPython3.7より性能が高く、SharedMemoryを使うためにPythonのバージョンを上げただけで
コードの改変なしに性能向上を得ることができました。


構成とタイムラインは下記を予定しています。

■導入(3分)
・自己紹介
・何をしたいのか
・実機デモ

■軽量な認識モデルの作成(6分)
・代表的な物体検出モデルの紹介(R-CNN/YOLO/SSD)
・今回作成したYOLOベースのモデル紹介
・精度を上げるための学習手法の工夫
   - 学習の進み具合に応じて自動的にミニバッチサイズを増やす
   - 転移学習を反復的に行う

■高速に推論を行うための環境構築(5分)
・推論を高速に行うためのONNX Runtime導入
・multiprocessingモジュールによるデータの処理パイプライン化
・最新のPythonは最速のPython
   - 3.8から導入されたshared memoryによる、高速なプロセス間データ受け渡し
   - Python自体の速度改善

■質疑応答(1分)",Yutaka Nakano,全文検索とログデータの集計処理を生業とするサーバサイドエンジニアです。
203959,ASGI（非同期サーバゲートウェイインターフェース）の概要,#pyconjp_3,2,1,"大成功した WSGI に後継の仕様が出たらしい。そんな話をご存知でしょうか。

サーバーとフレームワークのエコシステムが独立して存在しているWSGI ですが、WSGIは WebSocketや新しい async/await 構文をサポートできていません。

その問題を解決したWSGI のスピリチュアルな後継であるASGI は、WebSocketと非同期サポートが組み込まれています。

このセッションでは、よくわからないけど気になる存在のASGIについて、WSGIと対比しながら実際のコードを交えて概要を紹介したいと思います。
","Pythonを使ってWebアプリケーションを実装し、WSGIを使ったWebサーバ環境を構築したことがある経験。
トークで扱うASGIについて、Read the Docsを一読いただいていると理解しやすいと考えますが、必須ではありません。
","* WSGIとASGIの違い
* ASGIでできることの理解
* ASGIサーバ導入の前提知識",Talk(45min),Intermediate,0%,Web programming (including web frameworks),Japanese,Japanese only,"ASGI（非同期サーバゲートウェイインターフェース）の概要を、WSGIとの違いの比較を交えて紹介します。

- 導入（3min）
    - 自己紹介

- WSGIについて（15min）
    - 概要 (基本のコードの紹介)
    - WSGIエコシステムサーバ(Gunicorn, uWSGI, mod_wsgi)とFramework (Flask, Django2.x)
    - WSGI の制限例: WebSocket

- ASGIについて（25min）
    - ASGIの紹介(基本のコードの紹介)
    - ASGIの開発と歴史
    - ASGI 機能、WebSocket、HTTP/2
    - ASGIのエコシステムサーバ(Hypercorn, Daphne, Uvicorn) とFramework(Starlette, Django3.x, Quart)
",Junya Fukuda,"Pythonエンジニア
PyCon Kyushu 2020 Kumamoto トーク採択"
203111,Pythonで作る機械学習システムパターン,#pyconjp_5,2,1,Pythonを用いた機械学習のモデル開発事例は多数ありますが、そのモデルをビジネスやシステムに組み込み、運用する事例は多くありません。機械学習を有効活用するためにはシステム化することが必要と考え、そうした問題意識から、機械学習システムのデザインパターン集を公開しました。本セッションでは、機械学習システムのグランドデザインおよびPythonによる機械学習デザインパターンの実装例を説明し、システムの運用や改善ノウハウを共有します。プラットフォームにはKubernetesを活用し、機械学習の学習からテスト、QAを行い、推論器をリリースして運用するまでの一連の流れを説明します。,"- 機械学習の基礎知識
- Webアプリケーションの基礎知識","- 機械学習を実用化する方法
- Pythonによる機械学習ワークフローおよびWebアプリケーション開発
- ログ設計
- システムの運用ノウハウ",Talk(45min),Intermediate,50%,Data Science / Machine Learning,Japanese,Japanese only,"本セッションでは機械学習のモデルを実用化するためのノウハウをPythonによる実装を交えて説明します。
Pythonを用いた機械学習のモデル開発事例は多数ありますが、そのモデルをビジネスやシステムに組み込み、運用する事例は多くありません。機械学習を有効活用するためにはシステム化することが必要と考え、そうした問題意識から、機械学習システムのデザインパターン集を公開しました。
https://github.com/mercari/ml-system-design-pattern

機械学習システムのグランドデザインおよびPythonによる機械学習デザインパターンの実装例を説明し、システムの運用や改善ノウハウを共有します。プラットフォームにはKubernetesを活用し、機械学習の学習からテスト、QAを行い、推論器をリリースして運用するまでの一連の流れを説明します。

構成とタイムラインは以下のとおりです（45分想定）。
1. 自己紹介（5分）
2. 機械学習システムデザインパターンの紹介（10分）
- 機械学習をシステムに組み込むための課題
- 課題解決のアプローチ
- デザインパターンの意義
- 機械学習システムのコンポーネント
3. 機械学習システムの実装、リリース、運用方法（25分）
- 学習パイプライン
- モデルの評価
- 推論器の実装
- リリース前QAおよびパフォーマンスチューニング
- A/Bテスト
- 評価
4. まとめと質疑応答（5分）",Yusuke Shibui,"株式会社メルカリ
MLOps, Image Search & Edge AI
文学修士(イギリス旅行史) →富士通→IBM→SAS→パナソニック→株式会社メルカリ
■ 機械学習によるサービス改善
■ 機械学習プラットフォーム開発
■ Edge AI
写真の物体検出結果：猫:0.55 犬:0.45 人間:0.60 謎:0.40"
203899,Understanding Python's Debugging Internals,#pyconjp_2,2,1,"During this session, we’ll share how debugging actually works in Python, delving into how Python debugging looks like from the inside. We will discuss the differences between CPython and PyPy interpreters, as well as explaining the underlying debugging mechanism, and ultimately how to utilize this knowledge at work. ",Use and understand Python,"The differences between CPython and PyPy interpreters, understanding performance benchmarks, the sys.set_trace function (how to use it and alternatives to it) and ultimately how to utilize this knowledge.",Talk(45min),Intermediate,50%,Python core,English,English only,"Ever wondered how Python debugging looks on the inside? On our journey to building a Python debugger, we learned a lot about its internals, quirks and more. During this session, we’ll share how debugging actually works in Python. We’ll discuss the differences between CPython and PyPy interpreters, explain the underlying debugging mechanism and show you how to utilize this knowledge at work and up your watercooler talks game.",Liran Haimovitch,"Liran is the Co-Founder and CTO of Rookout. He’s an advocate of modern software methodologies like agile, lean and devops. Liran’s passion is to understand how software actually works. When he's not thinking of code, he's usually diving or hiking. "
203063,レトロゲームエンジン「Pyxel」でゲームプログラミングをはじめよう！,#pyconjp_4,2,1,"レトロゲームエンジン「Pyxel」をご存知ですか？
Pyxelはドット絵を使ったゲームを簡単に作成できる、Pythonのライブラリです。
シンプルでわかりやすい命令と、画像と音楽の制作ツールも同梱されている手軽さから、全世界でユーザーが増えており、GitHubでは7000スターを獲得、全言語のゲームエンジン中Top10入りしています。
本トークでは、Pyxelの開発者本人(日本人です)が、Pyxelの導入方法、付属ツールを使ったゲーム素材の作り方、Pyxelを使った本格的なゲームプログラミングの方法について解説します。
Pyxelで手軽に楽しくゲームプログラミングを始めましょう！",Pythonによる簡単なプログラムの作成経験,"・レトロゲームエンジンPyxelの使用方法
・ゲームプログラミングの基本的な考え方
・Pyxelを使ったゲームゲームプログラミングの方法
・Pyxelを使ったゲーム素材（画像・サウンド）の作成方法",Talk(30min),Beginner,0%,GUI and games,Japanese,Both,"Python向けレトロゲームエンジン「Pyxel」を使ったゲームプログラミングの方法について、導入方法から本格的なゲームの作り方まで、以下のステップに分けて説明します。

1. Pyxelの概要と導入 (5分)
 - Fantasy Consoleについて
 - Pyxelの特長・制作事例
 - Pyxelの導入方法

2. Pyxelを使ったお絵描きプログラムの作成 (8分)
 - お絵描きプログラムの作り方
 - 基本的なAPI
 - お絵描きプログラムの実践

3. 付属ツールを使った素材の作成 (5分)
 - Pyxelのリソースデータについて
 - Pyxel Editorの機能紹介
 - 画像データの作成方法
 - サウンドデータの作成方法

4.  本格的なゲームプログラミングの方法 (9分)
 - ゲームプログラムの考え方
 - ゲームプログラミングに必要な仕組み
 - Pyxelでの作成例
 - ゲームジャンルごとのポイント紹介

5. まとめ (3min)
 - 解説内容のまとめ
 - Pyxelの今後",Takashi Kitao,"元ゲーム開発者。メタルギアソリッドのプランナー、PS2向けロボットシューティング「Zone of Enders」シリーズのゲームデザインとメインプログラマーを担当。
現在は電機メーカーにてAR/VR技術を研究開発中。
レトロゲームエンジンPyxelの開発者。2018年、GitHubデイリーランキングにて全世界の開発者中1位を獲得（ただし3日間だけ…）"
203053,How to Transform Research Oriented Code into Machine Learning APIs with Python,#pyconjp_5,2,2,"Recently, Python engineers have more opportunities to work with data scientists than before. At the same time, they are often faced with the research-oriented code written by researchers or data scientists. In order to integrate this code with systems such as APIs, python engineers need to additionally write the code or refactor it, and make them work on the server.

This talk covers the gap between the research-oriented code and production code of machine learning API. What is the gap between them? How it can be implemented based on real-world python code? How can the code validate whether the dataset is correct ? How can machine learning models be continuously inspected? Audiences can earn the answers to these questions from this talk.","1) The audiences can be engineers, data scientists, or researchers at junior or middle level who use python.
2) This talk could be more beneficial for people who have experience to be involved with AI / ML projects.

Tech Stacks that it might be good for audiences to have:
- Basic understanding of python grammar 
- Knowledge about python for analysis use
- Architecture of RESTful API
- Experience exploratory analyzing data or doing data mining with python","One of the major things that the talk can provide could be that audiences would learn each responsibility of each role in AI / ML projects and process to implement AI / ML products, and the better or best practices of ML API implementation.",Talk(30min),Intermediate,50%,Data Science / Machine Learning,English,English only,"Introduction

Why do I talk about this topic ? (1 minute)
- The Four Steps to transform Research Oriented Code into 
- Machine Learning APIs with Python (1 minute)

Main Talk (+ sample codes and explanations in each section)

1) Understand what code you look at and make, and how to handle the code. (6 minutes)
- What is Research Oriented Code ?
- What are ML APIs ?
- How should engineers handle research oriented code ?

2) Modularize research oriented code (6 minutes)
- Categorize research oriented code into preparation code, preprocessing code, and ML code
- Break them out into functions and make them testable
- Clarify input and output of the code, and define URI

3) Refactor research oriented code (6 minutes)
- Prepare for refactoring by understanding requirements of each code and taking notes about them
- Simplify I/O code in preparation code
- Transform coding style with pandas into purely pythonic code in preprocessing code

4) Check the ML APIs can work correctly on the server (6 minutes)
- Write decorators to automatically check parameters
- Set up production-like environments
- Suggest a tiny example of CI/CD environments for ML APIs.

Summarize the talk

Quickly review the four steps to transform Research Oriented 
- Code into Machine Learning APIs with Python (1 minute)
- Share the useful resources and tips related to what is mentioned in the talk. (1 minute)",Tetsuya Jesse Hirata,"Tetsuya is a software engineer based in Tokyo. He has been involved with several AI/ML projects in EdTech domain and has mainly been implementing ML APIs and ML Ops environment. Prior to this, he used to research the relationships between online learning behaviors and learning outcomes at the UCL Institute of Education (IOE) in the UK. His interest is in how to bridge the gap between data science and engineering.

https://www.linkedin.com/in/tetsuya-hirata-a31b52134/
https://twitter.com/JesseTetsuya
https://medium.com/@JesseTetsuya"
203900,Sphinx はどのように Python コードからドキュメントを生成するのか,#pyconjp_4,2,2,Sphinx では Python コードからドキュメントを生成するために、静的解析や動的解析といったアプローチを用いてプログラムをあらゆる側面から解析しています。本セッションではその手法を紹介します。Python コードから得られる情報を元に、あなたも便利なツールを作ってみませんか。,"* Python のプログラムを開発した経験があること
* Python の型ヒントを使ったことがあるとなおよい","* Python オブジェクトが持つメタデータの知識
* 動的解析、静的解析の方法",Talk(30min),Advanced,0%,Python core,Japanese,English only,"Sphinx は Python の公式ドキュメントや numpy, pandas, django など数多くのプロジェクトで利用されているドキュメント生成ツールです。

Sphinx が広く利用されている理由のひとつに Python プログラムからのドキュメント自動生成(autodoc)があります。ドキュメント自動生成機能を用いると、手元の Python コードからかんたんにドキュメントを生成できます。本セッションではこのドキュメント自動生成機能がどのように実装されているのかにフォーカスを当て、Python プログラムの動的解析および静的解析の実装方法をご紹介します。

発表内容:
* Sphinx とはなにか
* Python コードからドキュメントを生成する
* Python オブジェクトから情報を抽出する (動的解析)
* Python のスペシャルメソッドを理解する
* PEP を読む
* Python コードから情報を抽出する (静的解析)
* AST の使い方
* Python のバージョン差と戦う
* 質疑応答",tk0miya,(株)タイムインターメディア CTO。Sphinx-Users.jpの運営のひとり。ドキュメンテーションツールSphinxのコミッター、作図ツールblockdiagの作者。他にも数多くのSphinx拡張(プラグイン)を開発している、ドキュメンテーションツールを主戦場とするOSS開発者。 著書：「Sphinxをはじめよう第2版（2017 オライリー・ジャパン刊）」。
203858,チーム開発立ち上げにやっておいたほうがいいソース管理の方法,#pyconjp_3,2,2,"プログラミングを動かす上で必要なことはアルゴリズムだけではなく、綺麗に書くこと、そしてそれらをチェックする正しい仕組みが必要です。
特にチーム開発の場合、正しく動いていたとしても人によって書き方がばらばらになってしまい、結果として見にくいソースになってしまうことがあります。
それらを防ぐ方法としてPythonのコード規約(PEP8など)と仕組み(flake8, black, pre-commitなど)があります。
ここではそれらの使い方だけはなく仕組みも紹介しようと思います。",Pythonの初級文法,(特に)チーム開発時におけるコード管理の方法,Talk(30min),Beginner,0%,Tips of development with Python,Japanese,Japanese only,"Pythonのソースコードを綺麗に保つためのいくつかの方法について説明します。
- 対象
  - チーム開発で新規プロジェクトを立ち上げる方
  - ソース管理はきっちりやりたい方(""""と''が混在して欲しくない等)
  - 耳学問でpep8とかflake8とか訊いたことがあるけどよく分からない方
  - formatterで内容は分からないけど適当に他のプロジェクトで使ってるものを使い回してる方

この登壇ではPythonのコーディング規約であるPEP8に付いての簡単な説明から、flake8のようなラッパーツール、
blackのようなformatterそしてそれらを自動で適用させるためのpre-commit、そしてそこに導入するべき他のformatter(mypyやseed-isort-configなど)に付いて簡単に説明し、ソースをどのように修正してくれるのかなどを実例を示しながら説明していきたいと思います。

構成とタイムラインは以下のとおりです。
- 導入（3min）
    - 自己紹介
    - 問題意識
       - チーム開発の場合、どうしても個人の癖がでてしまい、全体としてルールが統一がされていないことがある。 また開発環境の違いによっては警告がでる人と出ない人の差などがあり不快感もある。
       レビューの際もそうした本質的ではない部分で指摘することは時間の無駄となっている。
- Pythonのコーディング規約pep8に付いて(5min)
    - pep8とはなにか？
    - 実例紹介
- formatterについて（10min）
    - autopepについての説明と実例
    - blackについての説明と実例
    − yapfについての説明と実例
    - それぞれの比較
- pre-commitでformatterを自動化(8min)
   - 指定方法の実例
   - 上記の他に指定しておくといいものの紹介
       - seed-isort-confingやmypyなど
 - まとめ (1min)
- 質疑応答 (3min)
",yuuki nakajima,Python歴5年、主にDjangoを書きつつインフラの面倒も見たりするミニフルスタックエンジニア
203648,ひとりで作る画像検索システム,#pyconjp_2,2,2,"これは、画像をクエリとする検索に興味を持っている人のためのトークです。画像そのものをクエリとする画像検索のノウハウはまだまだ多くありません。画像を画像で検索する技術は、ユーザー体験を向上させる可能性を持っています。アップロードした画像からユーザーの入力を補助したり、ユーザーの求める商品と似たような見た目の商品を推薦したり、ユーザーへより良い体験を提供できます。

本トークでは、画像検索システムを構築するために必要な原理の紹介と、実際に検討した Python パッケージを紹介します。","・Python の何らかのパッケージを使ってプログラムを作成した経験
・Python で画像処理をした経験があれば、すぐに実践できると思いますが、必須ではありません","・類似画像検索に必要な知識やシステム構成
・画像処理や検索に便利なパッケージ",Talk(30min),Intermediate,0%,Case studies (excluding web programming or machine learning),Japanese,Japanese only,"画像検索の手法は2つに大別できます。画像に紐付いたテキスト情報を検索するTBIR(Text Based Information Retrieval)と、画像そのものをクエリとして検索するCBIR(Contents Based Information Retrieval)の2つです。

本トークでは、個人でCBIRの画像検索システムを Python で作成した事例を紹介します。

画像検索システムを作るためには、画像処理及びベクトル検索の知識と技術が必要です。幸いにも Python は画像処理やベクトルを簡単に扱えるパッケージが豊富にあります。

私は、画像検索がどのように実現されうるか独自に調査し、得た知識を使って画像検索システムを作成しました。

本トークでは、画像検索を実現するために調査して得た原理や、実際に使用検討したパッケージに関連する知見を共有します。

構成とタイムラインは以下のとおりです。

・導入（5min）
・・自己紹介
・・類似画像検索の課題
・画像検索の手法（10min）
・・画像が似ているとはどういうことか
・・特徴量の抽出と検索が重要な技術ポイント
・・抽出の手法とライブラリ(pHash, AKAZE, DNNなど)
・・検索の手法とライブラリ(faiss, nmslib, annoyなど)
・画像検索システムを作る（10min）
・・システム構成(ユースケース図とシーケンス図）
・・Python で画像から特徴量を抽出する
・・Python で特徴量を検索できるようにインデックスする
・・特徴量抽出と登録を定期実行する
・・選定したライブラリのアルゴリズム
・まとめ (1min)
・質疑応答 (4min)",康貴 山際,"学生時代に画像収集や画像処理を趣味で始める。ピクシブ株式会社にウェブエンジニアとして入社し、広告配信システム開発運用に携従事。
趣味が高じて、屋内での画像処理に関して武蔵野大学と共同研究し、のちに同大学の客員研究員となる。
その後、OLTA株式会社にウェブエンジニアとして入社し、クラウドファクタリングの事業に従事している。"
202353,BLEでロボットトイを制御しよう,#pyconjp_3,2,3,"STEAM教育が流行る中、教材として様々なモノが増えてきています。

これらの教材にはGUIを用いたプログラミング環境や開発者向けのAPIが公開されています。
しかし、これらの教材はおもちゃのように動くモノが多く、低いレイヤーの制御が必要なので、Webアプリケーション開発者には取っつきづらいこともあります。

このトークでは、教材が公開している技術仕様をもとにpythonでBLE制御するユースケースを共有します。

OSSで公開されているライブラリを用いた２つの方法でBLEを制御する方法が理解できます。","pythonを用いた開発を行ったことがある経験

BLEの知識があった方がトークの内容を理解しやすいと考えますが、必須の前提知識はありません。","python でのバイナリデータ操作の仕方
BLE 操作の基礎知識
pyobjc を用いた BLE 操作の仕方",Talk(30min),Intermediate,50%,Case studies (excluding web programming or machine learning),Japanese,Japanese only,"まず導入で、トークの目的について話します。

STEAM 教育が流行る中、教材として様々なモノが増えてきています。
これらの教材には GUI を用いたプログラミング環境や開発者向けの API が公開されています。
しかし、低いレイヤーの制御が必要なので、取っつきづらいこともあります。
これらを解決する一助とすることが目的です。

いくつか教材があるのですが、STEAM 教育のコンテンツとしては実際に動いた方が分かりやすいと
考えているので、Cozmo や toio が良いと考えています。Cozmo はサービスが停止しているため、
今回は toio を用いた例で説明を行いたいと思います。

今回のトークのため、toio を制御するライブラリを作成しました。
実際に Python で BLE ライブラリを操作するためにはバイナリデータを扱うので、
基本的な利用方法(bytes、bytearray や struct)について説明します。
BLE ライブラリとしては Adafruit_BluefruitLE と bleak の 2 つで実際の制御するコードを説明します。

ここで１つ課題が発生します。toio には toio.js という typescript で書かれたライブラリがあり、
それと同じような振る舞いを考えていたのですが、上記の２つのライブラリではうまく動作しませんでした。
これらを解決するために２つライブラリが利用している「pyobjc」というライブラリを用いて制御する
ことを考えました。
最後に pyobjc を用いた BLE の制御方法についてコードで説明します。


- はじめに（2min）
　- 自己紹介
- 導入（3min）
　- 本トークの目的
　- 様々な教材
- BLE ライブラリ で 制御する（10min）
　- バイナリデータを扱う
　- BLE を操作する
　- BLE ライブラリ で発生した課題
- pyobjc で制御する（12min）
　- pyobjc とは
　- corebluetooth を制御する
- まとめ（3min）",sandfish03,"SaaS企業でサーバサイドエンジニアをやっています。
仕事ではpython使ってはいないですが、pythonが好きです。"
203923,Cloud RunとFastAPIで、ChatBotをミニマムスタートしよう,#pyconjp_4,2,3,"Chatbotの開発・運用には様々なアプローチが存在しています。今回は、「Slackbotの開発」のユースケースとして、「Cloud Run + Fast API」というパターンをプロダクトの特性を活かしつつ紹介します。
このユースケースを通じて、Cloud Runの使いどころや、非同期処理(async)の利点・利用例をふんわり理解しましょう。","- Dockerの基礎知識(build, run, pushの概要がわかる程度)
- (要求度:低)上記を元にした、DockerコンテナベースでのPython Webアプリケーションの知識
","- Cloud Runの使い方
- Fast APIを用いたアプリケーションの作り方
- Slackbotを始めとした、チャットボット用のWebアプリケーション開発時の基本的な作法例",Talk(30min),Intermediate,0%,Web programming (including web frameworks),Japanese,Japanese only,"新型コロナウイルスの影響もあり、チャットプラットフォームは今までより更に一段重要性が上がってきています。
個人・企業を問わず様々なレイヤーの人が、「チャットボット」を作るようになってくるのではないでしょうか。

今回は、「GCP上にFastAPIを使ってSlackbotを開発する」という主題を元に、Chatbotをスタートさせる事例と勘所を紹介します。


- 起: 自己紹介
- 起: 今回の主題
  - 「Google Cloud Run上」に「Fast APIをベースにしたWebapp」として「Slackbot」を開発・提供する
  - この組み合わせを選んだ理由（概要レベル）
- 承: Google Cloud Run
  - Cloud Runとはなにか
  - どんな特性があるか
  - 今回、なぜこれを使うか
- 承: Slackbot
  - 現在のSlackbotの動向
  - RTMPではなくEventAPIを選ぶということ
- 承: Fast API
  - Fast APIとはなにか(ミニマムな使い方)
  - どんな特性があるか(本題に近い部分を中心に)
  - 今回、なぜこれを使うか
- 承: 実例を交えた解説
  - デモ
  - エンドポイントの開発
  - メッセージに応じて振る舞いを変える
  - Slackbot用APIの制約との戦い
- 転: 悩ましい部分
- (転: 派生する未来)
- 結: まとめ",Kazuya Takei,ニジボックス所属のインフラ寄りバックエンド系スタックフルエンジニア。 興味にリソースを振りがちで、最近はSphinxとFastAPI系に戯れてる機会が多め
201486,Your Escape Plan From Numpy + Cython,#pyconjp_2,2,3,"In this talk, a math equation will be given as a benchmark. Instead of optimizing it with Cython (painful and unpythonic), I will give three Pythonic solutions to accelerate NumPy. At the end, the pros and cons of three solutions will be given as well as some recommendations based on my experience.",The audience must have some development experience with NumPy.,"* Three pythonic solutions to boost NumPy performance with little modification
* A big picture of performance improvement of three commonly used NumPy accelerate solutions: CuPy, Numba, and Pythran
* Which solution should be applied first in different scenarios
* Bonus: an interesting solution: Transonic",Talk(30min),Advanced,50%,Data Science / Machine Learning,English,English only,"If you've been a data scientist or researcher long enough, you must have encountered a situation where your NumPy code ran quickly on small datasets in a testing environment but performed poorly on real-world datasets (100x larger or more). In this talk, I will introduce three Pythonic solutions to improve NumPy performance drastically without modifying too many codes.

At the beginning of the talk, a math equation: logsumexp, which is widely used in machine learning, will be illustrated. I will show how it is implemented with pure NumPy and use it as a benchmark so we can compare it to three proposed solutions at the end of the talk.

Then, three solutions: CuPy, Numba, and Pythran will be presented in separate sections. In each section, I will give a brief introduction to the solution and show how to apply this solution to our benchmark code.

At the end of the talk, I will compare these solutions from different aspects:
* How much performance is boosted after each solution is applied
* Ease to apply on your existing code (including the ease of debugging)
* Limitations of each solution
* Which solution should be applied first in given scenarios

Last but not the least, I will show a relatively new but interesting solution: Transonic to the audience so they can give it a try on their side project.

Outline and timeline are as follows:
- Introduction (4 min)
   - Self-introduction
   - Explain why this issue is important but painful
   - Explain logsumexp in math equation
   - Show how logsumexp is implemeted by Numpy
- Solution 1: CuPy (4 min)
   - Introduce how to use CuPy and its limitation
   - Show how logsumexp is implemeted by CuPy
- Solution 2: Numba (4 min)
   - Introduce how to use it and its limitation
   - Show how logsumexp is implemeted by Numba
- Solution 3: Pythran (4 min)
   - Introduce how to use it and its limitation
   - Show how logsumexp is implemeted by Pythran
- Compare three solutions (11 min)   
   - Show performance differences among solutions
   - Share my experience on these solutions
   - Give some recommendations on choosing solutions based on different scenarios
- Bonus, Takeaways, and QA (3 min)
   - Briefly mention ""transonic"" project (a combined solution of CuPy, Numba and Pythran)
   - Takeaways
   - QA",clyang,"A Python performance tuning enthusiast tweaks ML platform for Cybersecurity company. Meanwhile, I'm also a cybersecurity hobbyist poking websites on the Internet."
203938,広島における地域 Python コミュニティの立ち上げ方と続け方,#pyconjp_1,2,3,"PyCon JP は毎年東京でカンファレンスを開催するだけではなく、
Python Boot Camp の開催や地域イベントの支援などの取り組みも行っています。
それらの制度をどのように活用しながら、
自分の地域で Python のコミュニティ活動を立ち上げて、続けていけばいいでしょうか？
このような活動はどんな人に向いているでしょうか？
どんなメリットがあるでしょうか？
このトークでは一緒に活動を続けている仲間で、広島のコミュニティ活動を紹介します。
「自分も地元で Python のコミュニティ活動をやってみたい」
という人に一歩踏み出すきっかけになっていただけると嬉しいです。",なし,"- PyCon JP が行っている地域コミュニティ支援
- 地域 Python / PyCon (mini) イベントの運営
- Python Boot Camp の開催とフォローアップ
- 他の地域 Python コミュニティや PyCon JP コミュニティとのつながり方
- IT勉強会のオンライン化のもたらすチャンスと地域コミュニティの役割
- 広島のコミュニティのメンバーによる体験談や技術紹介",Talk(30min),Beginner,0%,Community building related to Python,Japanese,Japanese only,"広島では 2015 年に PyCon mini Hiroshima カンファレンスを、
2016年に Python Boot Camp を開催し、
毎月の小規模の勉強会とほぼ毎年のカンファレンスを継続しています。
私たちは PyCon JP の制度や支援に支えられ、
また県内外の Python 関係者に支えられてきました。
仲間が増えるとイベントも運営しやすくなり、
全国の人とつながる機会もさらに増えていきます。
2020年は多くのIT勉強会がオンラインで開催されており、
地方コミュニティの役割も変化していきそうです。
このトークでは広島の Python コミュニティの経験から、
地方でのコミュニティ活動の立ち上げや継続に役立つこと、
そして現状や今後の予定を紹介します。

構成とタイムラインは以下のとおりです。

- 広島での活動の紹介（10分）
 - PyCon mini Hiroshima
 - Python Boot Camp
 - すごい広島 with Python
 - PyCon JP への参加
- 共同発表者のトーク（5分）
 - いままで紹介したネタを振り返る
- 共同発表者のトーク（5分）
 - カンファレンスの参加者がスタッフになって気づいたこと
- 共同発表者のトーク（5分）
 - 東京のコミュニティから広島に移動した話
- クロージング（2分）
 - 地域 Python コミュニティで得たもの
 - PyCon mini Hiroshima の今後
- 質疑応答（3分）
","nishimotz, rhoboro, Ryo Mitsuda, Takayuki Kaisen","nishimotz：
2011年まで大学教員。現在は広島在住。NVDA 日本語チーム（オープンソースのスクリーンリーダー）、PyCon mini Hiroshima などのコミュニティ、ウェブアクセシビリティのWG委員、ソフトウェア開発者、技術チームのマネージャーなどとして活動中。2018年に株式会社シュアルタ設立。


rhoboro：
尾道が好きになり東京から尾道の向島に引っ越してきたフルリモートのプログラマ。学生時代からずっとPython好き。シンプルなコード、シンプルな設計を目指してます。

Ryo Mitsuda：
広島のITコミュニティで広く活動しています。 また、毎週水曜日に「すごい広島」というもくもく会を主催しています。

Takayuki Kaisen：
Pythonプログラマ"
203164,最先端自然言語処理ライブラリの最適な選択と有用な利用方法,#pyconjp_5,2,3,ここ数年、日本語を解析対象とする自然言語処理ライブラリが多く公開されています。BERTを手軽に利用できるTransformersなど、最先端の言語処理技術を利用できるライブラリの多くは、Pythonライブラリとして提供されています。しかし、多くのライブラリがリリースされる反面、ユーザー側の選択肢は増え、情報収集を含む技術選定コストが増加していることも事実です。そこで、本トークでは、日本語を解析対象とするPythonライブラリを整理し、利用シーンごとにライブラリを最適に選択する方法を説明します。日本語の文書分類タスクを通じて、コードの実装方法を説明し、各ライブラリの特徴や利点を解説します。,Python の基本的な使い方のみ知識として求めます。自然言語処理に関する知識は求めません。本トークでは、Google Colab で利用可能なサンプルコードを GitHub 上に公開することで、Python の前提知識によらず最先端の自然言語処理を体験できる内容を準備します。,"1. 自然言語処理の概要
2. 日本語言語処理における前処理の実装方法とその Tips
3. BERT を含む最先端文書分類モデルの実装方法
4. 利用シーンごとに最適な言語処理ライブラリを選択する方法
5. 最先端の言語処理技術を Python ライブラリ化する方法",Talk(30min),Beginner,0%,Data Science / Machine Learning,Japanese,Japanese only,"## トーク概要
ここ数年、日本語を解析対象とする自然言語処理ライブラリが多く公開されています。例えば、BERT を手軽に利用できる [Transformers](https://huggingface.co/transformers/index.html#)  、ニューラル言語処理向けトークナイザの [SentencePiece](https://github.com/google/sentencepiece) や単語依存構造解析が可能な [GiNZA](https://megagonlabs.github.io/ginza/)  など、最先端の言語処理技術を利用できるライブラリの多くは Python ライブラリとして提供されています。しかし、多くの Python ライブラリが世界中からリリースされる反面、ユーザー側のライブラリの選択肢は増え、情報収集を含む技術選定コストも増加しているかと思われます。

そこで、本トークでは自然言語処理の最新の研究動向を踏まえ、日本語を解析対象とする Python ライブラリを整理し、各利用シーン（Web開発、研究開発、勉強用）ごとに最適なライブラリを選択する方法を説明します。具体的には、文書分類タスクを通じて、コードの実装方法をチュートリアル形式で説明することにより、各ライブラリの特徴や利点を解説します。また、ライブラリの使い方を説明するだけではなく、映画レビューのデータセットを利用したライブラリの検証結果（精度、実行速度）を含め、どのように最先端の技術を Python ライブラリ化しているのか、Python ライブラリ実装の観点から見た特徴も解説します。

オンライン開催の利点を最大限に活用できるよう、本トークで説明するサンプルコードは Google Colab で利用可能な形式で GitHub 上に公開し、Python の前提知識によらず最先端の自然言語処理を体験できる内容を提供します。


## タイムラインと紹介ライブラリの一覧
- 導入（2min）
    - 自己紹介
    - 本トークの概要と目的説明
- 日本語言語処理における前処理の実装方法（10min）
    - 前処理の概要とその重要性の説明
    - 形態素解析器とサブワードトークナイザの紹介（[mecab-python3](https://github.com/SamuraiT/mecab-python3), [Janome](https://mocobeta.github.io/janome/), [nagisa](https://github.com/taishi-i/nagisa), [Stanza](https://github.com/stanfordnlp/stanza), [SudachiPy](https://github.com/WorksApplications/SudachiPy), [spaCy](https://spacy.io/), [GiNZA](https://megagonlabs.github.io/ginza/), [Juman++](https://github.com/ku-nlp/jumanpp), [KyTea](http://www.phontron.com/kytea/index-ja.html), [SentencePiece](https://github.com/google/sentencepiece)）
    - 各解析器の機能比較
    - 各解析器の実行速度比較
    - 各利用シーン（Web開発、研究開発、勉強用）を想定した前処理機能の実装方法の説明
- 映画レビューを分類する文書分類モデルの実装方法（14min）
    - 文書分類タスクの説明と応用事例の紹介
    - 学習器と分類アルゴリズムの紹介（[scikit-learn](https://scikit-learn.org/stable/), [spaCy](https://spacy.io/),  [Transformers](https://huggingface.co/transformers/index.html#), [AllenNLP](https://github.com/allenai/allennlp), [FLAIR](https://github.com/flairNLP/flair))
    - 検証用データセットの説明（[Yahoo Movie Reviews](https://github.com/dennybritz/sentiment-analysis)）
    - 各利用シーン（Web開発、研究開発、勉強用）を想定した文書分類モデルの実装方法と最適なライブラリの選択方法の説明
- まとめ(2min)
- 質疑応答(2min)",池田 大志,奈良先端科学技術大学院大学 自然言語処理学研究室（松本研）出身。 現在は企業にて、自然言語処理に関する研究開発に従事。
202455,How to plot unstructured mesh file on Jupyter Notebook,#pyconjp_1,2,4,"It is very important to plot the unstructured mesh and its data in scientific calculations. In Python, matplotlib is widely used to display results. However, there is not enough information abount plotting 2D and 3D unstructured grid meshes. This talk introduce the use of mayavi2 with the use of meshio and matplotlib and explains how to use them.","Jupyter Notebook
matplotlib","- How to read unstructured mesh data and how visualize in Jupyter Notebook.
- How to use mayavi2
- How to use meshio and matplotlib
- Developing information about meshioplt ",Talk(15min),Intermediate,50%,Anything else basically which doesn’t fall into the types of topics above,English,English only,"- Introduction (1min)
- Using library (10min)
  - mayavi2
  - meshio and matplotlib
- Examples (10min)
   - plotting unstructured 2D mesh and data
   - plotting unstructured 3D mesh and data
- development of meshioplt (5min)
- Summary (1min)
- Questions and answers (3min)",Tetsuo Koyama,"ARK Information Systems, INC. - Software Engineer (2012-)"
203957,NumPy/pandas使いのためのテスト自動化入門,#pyconjp_5,2,4,"本トークでは、Pythonを使って数値実験やデータ処理を行う人に対して、NumPyやpandasに備わっているテスト機能について紹介します。
JupyterNotebook上で試行錯誤しながらデータを扱う人にとって、テスト自動化の習慣は馴染みが薄いかもしれません。しかし書き捨てのコードが増えてくると、プログラムの結果に自信が持てなくなってきます。そんなとき、テストが自動化された.pyファイルに処理を移せると、本来の実験や分析に集中できるようになります。
開発と実験のテストでは、同じ部分もあれば異なる部分もあります。 本トークでは、NumPyやpandasのテストについてTipsを紹介します。",- NumPyやpandasを使った経験があること,"- NumPyやpandasを扱うプログラムをテストする上でのTips
",Talk(15min),Intermediate,0%,Data Science / Machine Learning,Japanese,Japanese only,"本トークでは、Pythonを使って数値実験やデータ処理を行う人を対象に、NumPyやpandasに備わっているテストのための機能について紹介します。

▼内容
1. 導入 (30秒)
2. Jupyter Notebookから.pyへ (3分)
  - データ使いでもテストを書くメリット
  - 開発におけるテストとの違い
  - テストを書きやすいところ
3. pytest (2分)
4. NumPyのためのテスト (4分)
5. pandasのためのテスト (4分)
6. まとめ (30秒)",komo_fr,大学では知能情報メディアを専攻し、就職後はメーカーにてソフトウエア開発とPythonによるデータ活用のPoCや機械学習の取り組みを経験。科学技術計算分野へのPythonの活用に関心があり、現在は民間の会社でPythonを使ったデータ解析を、大学では研究のためのソフトウエア開発に従事。
202771,Pythonによる機械翻訳モデルの構築,#pyconjp_4,2,4,ディープラーニングの知識や実装経験はあるが、チュートリアルレベルから抜け出せない人に向けて、より実践的な内容にステップアップするための知見を紹介します。近年登場しているモデルは複雑化しており、その実装にはコーディングだけではなく、理論の理解、マシンリソースに関する知見が必須です。でもどうしたら難しい理論を理解し、マシンを適切に使いこなせるようになるのでしょうか、それはPythonと一緒に学ぶことです。このセッションでは、Pythonコードから理論を紐解き、理解する方法を紹介します。また、Google Colabで実際に手を動かしながらGPUやTPUの使用方法について解説します。," - TensorFlowの使用経験
 - ディープラーニングに関する基本的な知識
 - 自然言語処理に関する基本的な知識（尚可）"," - 実践的なディープラーニングの実装手法
 - 機械翻訳やTransformerなどの自然言語処理に関する知識
 - Google Colabの使い方
 - TPU（Tensor Processing Unit）を使用したモデルの実装方法
 - ハンズオンで使用するコード",Hands-on session(45min),Intermediate,50%,Data Science / Machine Learning,Japanese,Japanese only,"このセッションでは、Pythonで日本語を英語に翻訳する機械翻訳モデルを構築することを通して、実践的なディープラーニングの実装方法について学びます。まず、Transformerについて解説します。TransformerはBERTやGPT-2などに応用されており、近年の自然言語処理モデルを理解するためには欠かせない技術となっています。続いてソースコードリーディングを行い、Transformerに関する理解を深めます。ディープラーニングには数学がつきものですが、Pythonコードと一緒にモデルを追うことで、より直感的に理論を理解することができます。また、Google Colabを用いたハンズオンでは、TPUを使用するためのコードをPythonで実装します。ディープラーニングの効率的な学習にはGPUが必要ですが、最近はGPUだけでは計算しきれないモデルが登場しています。TPUはそういったモデルに有効であり、使いこなせるようになれば、ディープラーニング実装の幅が広がります。


発表の構成は以下の通りです。

# 導入（10min）
 - 自己紹介
 - このセッションの概要
 - Google Colabで実際にコードを動かしてみよう
  - 参加者はGPUで学習を実行し、機械翻訳でどんなことができるのかを確認します

# Transformerの解説（10min）
 - Transformerのモデルアーキテクチャを示す図を用いて解説
 - モデルの概要や機械翻訳の仕組みを解説

# ソースコードリーディング（10min）
 - Transformerのモデルアーキテクチャを示す図とPythonのソースコードを照らし合わせながら解説
 - ソースコードと同時に見ることで、理論の理解を深めます
  
# TPUで学習してみよう（10min）
 - TPUとは何か、GPUとの違いを説明します
 - TPUで学習するためのコードをPythonで実装します
  
# 質疑応答（5min）",拳人 川崎,"株式会社リーディング・エッジ社所属
自然言語処理とディープラーニングに関する研究開発をしています"
203568,Spec-driven development for REST API,#pyconjp_3,2,4,"API開発において、利用者向けのドキュメント
及び操作UIを提供するのは思いの外、大変な作業です。
特に内部向けのAPI開発の場合は時間もリソースも限られがちの為、あまり大掛かりなことはできません。
今回はconnexionを使うことでそれを実現したのでご紹介致します。
","RESTful APIの仕様、構造
flask開発の経験
swagger(OpenAPI)-uiの仕様
YAML記法","swagger-ui付きweb APIの作り方
（及びサンプル）",Talk(15min),Beginner,0%,Web programming (including web frameworks),Japanese,Japanese only,"PyCon JPのスタッフ活動ではSlackやGoogleドライブなどのツールを使います。
ツールについてイケていないと感じた点をPythonで解消した例を2つ紹介します。

基盤運用に向けて様々なAPI、wrapper開発が必要となります。
元々、ネットワーク機器・サーバ機器・ストレージ機器が持つAPIを利用するための
中間APIとして利用する為、かけられる工数、ドキュメント量の制限（少ない方が良い）等の制約があります。

従って、pythonに詳しくない人が容易に動作や仕様を想像できるような開発物が求められる為、
試行錯誤した結果、connexionというものに行き着きました。
PyConJPの中で恐縮ではありますが、よりPythonらしくない開発を行うことで
Pythonらしく無い人にもすんなり扱えるツールのご紹介ができればと思います。

構成とタイムラインは以下のとおりです。
※サンプルでは、構成を箇条書きで示し、大きな項目に所要時間の見積もりを付けることにします。

- 導入（2min）
    - 自己紹介
    - Python開発に至った経緯を紹介
    - 問題意識
- connexionを用いたweb API開発（10min）
    - API開発と操作ツールの同時開発（リリース）が求められる現場
    - なぜ、connexionか
     - できるだけ簡易なパッケージでなければならない
    - connexionを用いた開発の仕方
     - swagger.ymlを書き、そこからコードを呼ぶ
	- 開発例紹介
 - まとめ (1min)
- 質疑応答 (2min)",ainamori,"Akira Inamori
 - 大学卒業後、SI企業にて数年勤務した後にIIJへ入社。
 - IIJにて主に動画配信プラットフォームの設計・構築・運用に携わる
  - 動画配信基盤の構築・運用に辺りpuppet, Chef, Ansibleを経てpython nativeでの自動化に取り組む
 - 4年間のUS駐在を経て現在は社内向け基盤システム担当部署に帰任。現在はpythonにて社内システムの操作ツール、API開発を行う"
203944,詳解デコレータ ~実用的なデコレータを理解しよう~,#pyconjp_2,2,4,"pythonビギナーの方は、デコレータの理解や利用を後回しにしてしまうのではないでしょうか。
無理に使わなくても問題ありませんが、コードの読みやすさや量、繰り返し発生する認証処理などにはデコレータが向いています。
デコレータ記法に苦手意識のある方、これまで使ってこなかった方は、この機会に理解を深め、使えるようになりましょう。","市販のPython入門レベルのテキストを読み終えたレベル
これからPythonでweb開発を始めたい人","デコレータの理解と使い方
デコレータが使えるシチュエーションの知識",Talk(15min),Beginner,50%,Tips of development with Python,Japanese,Japanese only,"flask開発ではデコレータ記法が必須であり、それ以外にも応用の幅が広いデコレータですが、python入門書では基礎レベルを超えるためページ数が割かれていない感があります。入門者が自力で理解し使いこなせるようになるのは少しハードルが高いように感じるため、実用的なコード例を紹介しデコレータに親しんで欲しいと思います。

まず、デコレータの文法を手短におさらいし、シンタックスシュガーを使った表現まで解説します。

次に、実際にデコレータが使われるシーンを紹介します。
例１：ラッパーとしての利用、ログの記録、関数のパラメータを表示etc.
例２：flaskの使用例から、ルーティング、ログイン認証の実装を紹介

最後に、デコレータが2つ以上ある場合の解説をします。
日々使っていないと混乱してしまうと思うので、補足的に解説します。


- 導入 (2min)
   - 自己紹介
   - 課題意識
- デコレータの文法 (5min)
   - 高階関数の書き方、@を使った書き方
- デコレータの実用例 (5min)
   - 既存関数のwraping, 具体例2つ程度、
   - flaskでのデコレータ利用例、ルーティング、ログイン認証
   - ２つ以上のデコレータがある場合
- まとめ(1min)
- 質疑応答(2min)",Yosuke Nakabayashi,"実務経験のないアマチュアpythonista
はやくプロのpythonistaになりたい"
202587,Python(Cython) & OpenMPで高速並列処理,#pyconjp_2,2,5,"Pythonは遅いからCで組むといった言葉を時折耳にします｡
パフォーマンスは重要ですが､Pythonの豊富なパッケージを天秤にかけると悩ましいです｡
Cythonを使えば､Pythonを使ってC言語に匹敵する速度を出すことが出来ます｡更にOpenMPを使うことでループを並列化できます｡
これらのツールは一般的なPCは勿論のこと､スーパーコンピューターでも利用できます｡
Pythonの組みやすさと､Cの速さで膨大な計算に対処することを目指します｡","* 並列処理についての基礎的な知識
* Linux OSについての基礎的な知識","* Python(Cython)とOpenMPを使用した並列処理の方法
* CythonとOpenMPの手軽な導入方法(LinuxOS or GoogleColab)
* 簡単なPython(Cython & OpenMP)サンプルソースとそのURL
* スーパーコンピューターをトライアルユースする方法",Talk(15min),Intermediate,50%,Anything else basically which doesn’t fall into the types of topics above,Japanese,Japanese only,"　当セッションはCython(Python)とOpenMPの導入情報の説明をメインとして行います｡
　Cythonは変数や関数の定義､GILの扱いが少し特殊ですが､Pythonコードと共存できますし､pipで簡単にインストールできるので､
Pythonを使い慣れている方であれば､すぐにキャッチアップ出来ると考えております｡
　並列処理の手法は沢山ありますが､今回はOpenMPを題材とします｡Cythonにモジュールが用意されているので簡単に利用できます｡
これはスーパーコンピュータで利用されているツールの一つですが限定的に利用されるようなものではありません。
自宅ですぐに動作を試すことも出来ます。
　Cython及びOpenMPはJupyter Notebook(GoogleColab)でも利用できるのでコードと実行結果をお見せしながら説明していきます｡
　最後に､スーパーコンピューターのトライアルユースについて簡単に紹介します｡
一般のユーザーでも気軽に試すことが出来ることを実感頂いて､敷居を少し低くします｡
　商用利用など本格的な運用については色々と制約があるので､あまり踏み込みません｡
まずは体験してみて、継続利用についてはその後に各自が考えるという前提に立ちます。
　将来的な利用を視野に入れ､普段からハイスペックマシンを活用出来るようなコードの組み方に慣れておくことに価値を感じて頂きたいと思います｡

### 構成

#### 1. はじめに(1min)

* 自己紹介
* きっかけ

#### 2. Cython(6min)

* Cythonとは
* インストール手順
* Python構文と､Cython独自の構文を織り交ぜたコードの書き方
* コンパイルと実行の方法
* Jupyter Notebook(GoogleColab)での実行方法

#### 3. OpenMP(6min)

* OpenMPとは
* インストール手順
* prangeの使い方
* コンパイルと実行の方法
* Jupyter Notebook(GoogleColab)での実行方法

### 4. スーパーコンピュータ(2min)

* トライアルユースについて
* 使用感について",kenichi yoshimura,"｢pythonはいいぞ｣という言葉を見かけたのが全ての始まりでした｡
今ではしがないプログラマです｡"
203945,Python、ときどきRust,#pyconjp_3,2,5,"これまでPythonで性能を改善するために、CやC++を使うことには、なかなか踏み切れなかったりしていませんでしたか？
数年前に登場したRustは、速度や品質、並列の三拍子を揃え、ここ最近、注目を浴びている言語で、CやC++のように自分でガベージコレクションをしなくてもいいのも特徴です。 PythonからこのRustを呼び出すことで、処理を高速化させたり、逆に便利なPythonパッケージをRustから呼び出す方法を理解することで、生産性を落とさずに安全で高速なソフトウェア開発をする方法についてお話しします。","Rustというプログラム言語があることを知ってる人。
Pythonのようなスクリプト言語には、常にパフォーマンス問題がつきまとっていることを認識している人。",これまでよりも堅牢で信頼性の高いソフトウェアを開発する方法。,Talk(15min),Beginner,50%,Tips of development with Python,Japanese,Japanese only,PythonからRustを呼んだり、逆にRustからPythonを呼ぶことで、これまでよりも生産性を高めながら性能や品質の高いアーキテクチャを準備する方法についてお話しします。,あべんべん,"Institution for a Global Society（IGS）株式会社に所属（上席研究員）。今から13年前にIron Pythonを使って宇宙で実験する制御装置の開発に初めてPythonを使ったのがきっかけで、それ以降も適材適所で幅広く利用。
Start Python Clubやfin-pyなど8つのコミュニテイでスタッフの活動や、Pythonなどの技術書やビジネス書の監修・執筆・翻訳・査読なども行う。
Twitter: @abenben"
203893,インメモリー ストリーム活用術,#pyconjp_1,2,5,Pythonで巨大なテキストファイルやバイナリファイルを扱った経験はありませんか？標準モジュールであるioモジュールに含まれるインメモリー ストリームStringIOおよびBytesIOを使えば効率的に扱えるかもしれません。本発表ではインメモリー ストリームの便利な使い方やその限界についてお話します。,"Pythonでテキストファイルやバイナリファイルを取り扱った経験は必須です。具体的には組み込み関数openを使ったことがある人が対象です。
インメモリー ストリームに関しては説明するので前提知識は不要です。","- ioモジュールでテキストファイルやバイナリファイルを効率的に扱える方法、StringIOやBytesIOの限界について知ることができる
- 普段の業務に応用できる
- Pythonの標準モジュールの便利さを知ることができる。",Talk(15min),Intermediate,50%,Python core,Japanese,Both,"Pythonファイルオブジェクトを扱う標準的な方法は組み込み関数openですが、その背後にはioモジュールが存在します。
ioモジュールはPythonのストリーム（file オブジェクト）を扱うためのモジュールで、その中にインメモリストリームであるStringIOとBytesIOが含まれます。
本発表では、StringIOとBytesIOの使い方や実務を通して得た経験を伝えたいと思います。

- Pythonでファイルを扱う普通の方法：open()
    - open()は便利である
    - open()はDisk IOを伴う
- インメモリー ストリームStringIOおよびBytesIO
    - メモリ上のIOなので十分高速
    - メモリ上に載せるので巨大すぎると大変
- ケーススタディ：インターネット経由で巨大なファイルを取得して加工して戻す
    - 巨大なファイルをディスクに書き込むと時間がかかる
    - 大規模な分散システム基盤は使いたくないしそもそも存在しなかった
    - StringIOとBytesIOを駆使してメモリ上でZIP圧縮まで行う
- まとめ",Hayao Suzuki,"電気通信大学大学院 情報理工学研究科 総合情報学専攻 博士前期課程修了、修士（工学）。
株式会社アイリッジにてスマートフォンアプリのバックエンドサーバーをPythonやDjangoで開発している。"
203888,機械学習の実装から考えるオブジェクト指向,#pyconjp_5,2,5,"機械学習のモデルに関する実装をする中で、その複雑性に頭を抱える人は多いのではないでしょうか。
このトークでは、複雑な機械学習の実装を少しでも見通しよくするために、オブジェクト指向がどのように使用されているかについて2つ共有したいと思います。
1つ目はオブジェクト指向の三大要素について、機械学習の実装とどう関わっているか概念的なところを説明します。
2つ目は画像認識のモデルを例に実装において実際にオブジェクト指向がどのように機能しているかの説明したいと思います。
このトークを聞くことで、機械学習モデルの実装におけるオブジェクト指向の使用イメージをつかめることでしょう。","Pythonや何らかのプログラミング言語
機械学習の実装経験","・オブジェクト指向の三大要素である継承、カプセル化、ポリモーフィズムについての知識
・三大要素が機械学習の実装で実際に使用されている場面
・機械学習の実装においてオブジェクト指向が有意義であること",Talk(15min),Beginner,50%,Data Science / Machine Learning,Japanese,Japanese only,"機械学習のその処理の複雑さから実装が複雑になりがちです。
オブジェクト指向を意識して書くことで複雑な処理でも見通しが良くなり、メンテナンス性も向上したのでその話をさせていただきたいと思います。

まず、最初に機械学習の実装におけるオブジェクト指向の説明をします。
特に機械学習のモデルの実装をする上で、モデルによって共通する部分というのは少なからずできてくるので、それらをオブジェクト指向を使ってどのように実装しているかを話します。

次に、実際に実装例を画像認識のモデルを用いて説明します。
それぞれのモデルの実装の中で、どこがオブジェクト指向の要素なのかを紐解いていきます。

# 導入（3min）
## 自己紹介
## 問題意識

# 機械学習の実装におけるオブジェクト指向（6min）
## 機械学習の実装は複雑
## その解決方法としてのオブジェクト指向
## オブジェクト指向の三大要素
## 使用される場面

# 実装例（3min）
## 物体検出と超解像と姿勢推定を具体例に説明

# まとめ (1min)
# 質疑応答 (2min)",はんぺん,"# 自己紹介
- はんぺん([@hampen2929](https://twitter.com/hampen2929))

# 経歴
- 2015年3月	      東北大学工学部卒業
- 2016年	         Fraunhofer IISB (ドイツ留学)
- 2018年3月       東北大学大学院工学研究科卒業
- 2018年4月〜現在	IT系企業ので機械学習エンジニア

# テニス歴
- 2013年11月	  宮城県大会・準優勝(シングルス)
- 2014年2月	    宮城県学生選抜大会・ベスト4(シングルス)
- 2014年5月	    東北地区大会・ベスト8(シングルス)
- 2014年5月	    東北地区大会・準優勝(ダブルス)
- 2014年8月	    全日本学生テニス選手権大会出場(ダブルス)
- 2018年11月  	宮城県選抜ダブルス選手権大会ベスト4

# 興味
- 機械学習
- テニス
- 画像処理
- 動画分析

# 趣味
- テニスのフォームの分析
- テニスの試合映像からの人の位置と姿勢、ボールの位置、コートの位置の検出

# 連絡先
- yuya.mochimaru.ym@gmail.com

# URL
https://github.com/hampen2929/bio
"
